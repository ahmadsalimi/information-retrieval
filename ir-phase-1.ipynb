{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "<font face=\"XB Zar\" size=5>\n",
    "<div align=center>\n",
    "<font face=\"B Titr\" size=5>\n",
    "<p></p><p></p>\n",
    "بسمه تعالی\n",
    "<p></p>\n",
    "</font>\n",
    "<p></p>\n",
    "<font>\n",
    "<br>\n",
    "درس بازیابی پیشرفته اطلاعات\n",
    "<br>\n",
    "مدرس: دکتر سلیمانی\n",
    "</font>\n",
    "<p></p>\n",
    "<br>\n",
    "<font>\n",
    "<b>فاز اول پروژه</b>\n",
    "</font>\n",
    "<br>\n",
    "<br>\n",
    "موعد تحویل: ۸ فروردین <br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<font>\n",
    "دانشگاه صنعتی شریف\n",
    "<br>\n",
    "دانشکده مهندسی کامپیوتر\n",
    "<br>\n",
    "<br>\n",
    "</font>\n",
    "</div>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=6>\n",
    "    <h1>\n",
    "    <b>مقدمه</b>\n",
    "    </h1>\n",
    "    <p></p>\n",
    "    <p></p>\n",
    "</font>\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    پروژه‌ی درس متشکل از ۳ فاز است.\n",
    "    دادگان مورد استفاده در پروژه، مقالات علمی استخراج شده از سایت <a href=\"https://www.semanticscholar.org/\">Semantic Scholar</a> هستند. مقالات به دو دسته‌ی \n",
    "    «هوش مصنوعی , بیوانفورماتیک» و «سخت‌افزار و سیستم» \n",
    "    تقسیم شده‌اند. تخصصی بودن حوزه‌ی بازیابی می‌تواند به بهبود کیفیت آن کمک نماید.\n",
    "    <b><u>\n",
    "    پیش از هر چیز ابتدا یکی از این دو دسته را برای کار انتخاب نمایید.\n",
    "    </u></b>\n",
    "     امیدواریم تا انتهای پروژه بتوانید برای یکی از این دسته‌ها یک سیستم جست‌و‌جوی مقالات بسیار خوب پیاده‌سازی کنید.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=5>\n",
    "    <h1>\n",
    "    <b>فاز اول</b>\n",
    "    </h1>\n",
    "    <p></p>\n",
    "    <p></p>\n",
    "</font>\n",
    "<font face=\"XB Zar\" size=3>\n",
    "     <br>\n",
    "    هدف از فاز اول پروژه، طراحی و پیاده سازی سیستم بازیابی اطلاعات برای مجموعه دادگان ارائه شده است. در این فاز شناسه، چکیده و عنوان مقالات در اختیارتان قرار گرفته است.\n",
    "    در ابتدای هر بخش توضیح کوتاهی درباره آن بخش آورده شده است. در تمامی کد نیاز است که قسمت‌های TODO را کامل کنید. ملاک نمره دهی در این فاز صحت عملکرد توابع سیستم است. بنابراین از اجرا شدن کد خود اطمینان حاصل کنید و هر جا نیاز به توضیح بود می‌توانید به صورت کامنت یا در ادامه کد توضیح مربوطه خود را بنویسید (ارائه توضیح ضروری نیست و تنها در صورتی که شما احساس نیاز کردید، می‌توانید توضیح کوتاهی ارائه کنید. بنابراین ارائه توضیح نمره نخواهد داشت.) در زمان آپلود فراموش نکنید هر فایلی که نیاز است را آپلود کنید. نمره ی کامل این فاز ۱۰۰ بوده و مابقی امتیازیست.\n",
    "    <br>\n",
    "     تنها زبان قابل قبول برای پروژه پایتون است. محدودیت استفاده از کتاب‌خانه‌های آماده در هر بخش مشخص شده است. در انتهای پروژه قرار است یک سیستم یکپارچه‌ی جست‌و‌جو داشته باشید، بنابراین به پیاده‌سازی هر چه بهتر این فاز توجه داشته باشید.\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.5.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 42.8 MB 85 kB/s  eta 0:00:01     |████████████████████████████▊   | 38.4 MB 474 kB/s eta 0:00:10\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from en-core-web-md==3.5.0) (3.5.1)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.64.1)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\r\n",
      "Requirement already satisfied: setuptools in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (59.5.0)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\r\n",
      "Requirement already satisfied: jinja2 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\r\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.20.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (22.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.2)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.28.1)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.4.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2020.12.5)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.10)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.12)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ahmad/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.1)\r\n",
      "Installing collected packages: en-core-web-md\r\n",
      "Successfully installed en-core-web-md-3.5.0\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_md')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from functools import lru_cache\n",
    "import math\n",
    "from typing import List, Union, Literal, Dict, Set, Optional, Iterable\n",
    "from termcolor import colored\n",
    "import os\n",
    "\n",
    "from nltk.metrics import distance as nltkd\n",
    "import pandas as pd\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>پیش‌پردازش و آماده‌سازی داده‌ها (۶ + ۲ + ۱ نمره)</b>\n",
    "    </h1>\n",
    "</font>\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    در بخش اول ابتدا داده‌ها را از فایل خوانده و سپس با استفاده از کتابخانه‌های آماده‌ به پیش پردازش آنها بپردازید. در این قسمت نحوه پیاده سازی به شما برمی‌گردد. کتابخانه‌هایی که می‌توانید از آنها استفاده کنید <a href=\"https://spacy.io/\">SpaCy</a>  و <a href=\"https://www.nltk.org/\">NLTK</a>  است. \n",
    "    در این قسمت تابع clean_data() را پیاده سازی کنید. عملکرد تابع به این صورت است که یک متن به عنوان ورودی گرفته و توکن‌های ولید آن را به صورت یک لیست که عملیات lemmatization, stemming و case folding اجرا شده است خروجی می‌دهد. متن ورودی شامل عنوان مقاله یا چکیده آنهاست. \n",
    "    دقت کنید علائم نگارشی باید از متون حذف شده باشند. در قسمت بعد کلمات اضافه بی تاثیر را یافته و مطابق توضیحات عمل کنید.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Token:\n",
    "    processed: str\n",
    "    actual: str\n",
    "    i: int\n",
    "    idx: int\n",
    "\n",
    "    @staticmethod\n",
    "    def from_spacy_token(token) -> \"Token\":\n",
    "        return Token(token.lemma_.lower(), token.text, token.i, token.idx)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.processed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[an, abstract, be, a, summary, of, the, main, article]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 6 points\n",
    "\n",
    "def batch_clean_data(texts: List[str], batch_size: int = 128) -> List[List[Token]]:\n",
    "    \"\"\"Preprocesses the text with tokenization, case folding, stemming and lemmatization, and punctuations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : List[str]\n",
    "        A list of titles or abstracts of articles\n",
    "    batch_size : int, optional\n",
    "        The number of texts to be processed at a time, by default 128\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[List[Doc]]\n",
    "        A list of lists of tokens\n",
    "    \"\"\"\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    tokens = nlp.pipe(texts, batch_size=batch_size)\n",
    "    return [[Token.from_spacy_token(token) for token in doc if not token.is_punct] for doc in tokens]\n",
    "\n",
    "\n",
    "def clean_data(text: str) -> List[Token]:\n",
    "    \"\"\"Preprocesses the text with tokenization, case folding, stemming and lemmatization, and punctuations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The title or abstract of an article\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of tokens\n",
    "    \"\"\"\n",
    "    return batch_clean_data([text])[0]\n",
    "\n",
    "\n",
    "clean_data(\n",
    "    \"An abstract, \\\"is\\\" a summary of the main article.\")  # return [\"an\", \"abstract\", \"is\", \"a\", \"summary\", \"of\", \"the\", \"main\", \"article\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=3>\n",
    "در مرحله بعد تابع find_stop_words() را پیاده سازی کنید که کارکرد آن پیدا کردن توکن‌های اضافه است. \n",
    "توجه کنید که برای حذف stop wordها باید به گونه ای عمل کنید که ابتدا توکن‌های با بیشترین تکرار را  پیدا کرده و سپس به ۳۰ توکن با بیشترین تکرار را از میان تمامی توکن‌های متن حذف کنید. بدیهی است که stop word ها معمولا معنای زیادی همراه با خود ندارند. به این نکته در حذف آنها توجه کنید. در نهایت stop word هایی را که یافته‌اید به همراه تعداد دفعات تکرار به هر فرمتی در خروجی چاپ کنید. (۲ نمره)\n",
    "</font>\n",
    "</div>\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 points\n",
    "\n",
    "\n",
    "def find_stop_words(all_text: List[str], num_token: int = 30) -> Set[str]:\n",
    "    \"\"\"Detects stop-words\n",
    "\n",
    "     Parameters\n",
    "    ----------\n",
    "    all_text : list of all tokens\n",
    "        (result of clean_data(text) for all the text)\n",
    "\n",
    "    num_token : int\n",
    "        number of stop words to be detected\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Return Value is optional but must print the stop words and number of their occurence\n",
    "    \"\"\"\n",
    "    counter = Counter(all_text)\n",
    "    most_occur = counter.most_common(num_token)\n",
    "    print(pd.DataFrame(most_occur, columns=['token', 'count']))\n",
    "    return set([token for token, _ in most_occur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1 points\n",
    "\n",
    "\n",
    "class Corpus:\n",
    "\n",
    "    def __init__(self, dataset_name: Union[Literal['ai-bio'], Literal['hardware-system']], stop_topk: int = 30):\n",
    "        self.data = self.load_data(dataset_name)\n",
    "        self.stop_topk = stop_topk\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data(dataset_name: Union[Literal['ai-bio'], Literal['hardware-system']]) -> pd.DataFrame:\n",
    "        return pd.read_csv(os.path.join('data', dataset_name, 'data.csv'))[['paperId', 'title', 'abstract']]\n",
    "\n",
    "    @property\n",
    "    @lru_cache\n",
    "    def cleaned_documents(self) -> Dict[str, Dict[str, List[Token]]]:\n",
    "        return {\n",
    "            paper_id: {\n",
    "                'title': cleaned_titles,\n",
    "                'abstract': cleaned_abstracts,\n",
    "            }\n",
    "            for paper_id, cleaned_titles, cleaned_abstracts in zip(\n",
    "                self.data['paperId'],\n",
    "                batch_clean_data(self.data['title'].fillna('').tolist()),\n",
    "                batch_clean_data(self.data['abstract'].fillna('').tolist()),\n",
    "            )\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    @lru_cache\n",
    "    def stop_tokens(self) -> Set[str]:\n",
    "        return find_stop_words(\n",
    "            [token.processed\n",
    "             for tokens in self.cleaned_documents.values()\n",
    "             for token in tokens['title'] + tokens['abstract']],\n",
    "            num_token=self.stop_topk,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    @lru_cache\n",
    "    def non_stop_documents(self) -> Dict[str, Dict[str, List[Token]]]:\n",
    "        return {\n",
    "            paper_id: {\n",
    "                'title': [token for token in tokens['title'] if token.processed not in self.stop_tokens],\n",
    "                'abstract': [token for token in tokens['abstract'] if token.processed not in self.stop_tokens],\n",
    "            }\n",
    "            for paper_id, tokens in self.cleaned_documents.items()\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "ai_bio = Corpus('ai-bio')\n",
    "# hw_sys = Corpus('hardware-system')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      token  count\n",
      "0       the  43019\n",
      "1        of  32267\n",
      "2       and  28964\n",
      "3        be  21473\n",
      "4        in  19865\n",
      "5        to  17803\n",
      "6         a  15273\n",
      "7       for   9976\n",
      "8      with   8382\n",
      "9      that   6557\n",
      "10       we   6380\n",
      "11       on   5961\n",
      "12       by   4884\n",
      "13      use   4804\n",
      "14     this   4725\n",
      "15       as   4668\n",
      "16     have   4017\n",
      "17     cell   3791\n",
      "18    model   3770\n",
      "19       an   3498\n",
      "20     from   3482\n",
      "21   method   3156\n",
      "22     base   2907\n",
      "23    datum   2778\n",
      "24    study   2520\n",
      "25    image   2503\n",
      "26    which   2457\n",
      "27   result   2425\n",
      "28      can   2419\n",
      "29  patient   2188\n"
     ]
    }
   ],
   "source": [
    "# cache preprocess result for ai-bio\n",
    "_ = ai_bio.non_stop_documents"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# cache preprocess result for hardware-system\n",
    "# _ = hw_sys.non_stop_documents"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>نمایه‌سازی (۱۲ نمره)</b>\n",
    "    </h1>\n",
    "</font>\n",
    "<font face=\"XB Zar\" size=3>\n",
    "     در این بخش باید برای سامانه positional index بسازید.<br>\n",
    "    با توجه به مواردی که در بخش بعد می‌آید و نیاز به جست‌وجو‌ی مجزا و با امتیازدهی متفاوت بر روی بخش‌های مختلف سند مثل عنوان یا چکیده آن، در این قسمت باید نمایه‌ی مناسب برای امکان جست‌وجو‌ در بخش‌های مختلف پیاده‌سازی کنید. با استفاده از نمایه‌ی ساخته‌شده باید بتوان شماره تمامی اسنادی که یک کلمه در آن آمده است و همچنین همه جایگاه‌های این کلمه در هر بخش هر سند را پیدا کرد.<br>\n",
    "    \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.children: Dict[str, TrieNode] = {}\n",
    "        self.i_in_doc: Dict[str, Dict[Literal['title', 'abstract'], List[int]]] = {}\n",
    "        self.idx_in_doc: Dict[str, Dict[Literal['title', 'abstract'], List[int]]] = {}\n",
    "        self.is_end = False\n",
    "\n",
    "    def insert(self, doc_id: str, doc_section: Literal['title', 'abstract'], token: Token):\n",
    "        node = self\n",
    "        for char in token.processed:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "            if doc_id not in node.i_in_doc:\n",
    "                node.i_in_doc[doc_id] = {'title': [], 'abstract': []}\n",
    "                node.idx_in_doc[doc_id] = {'title': [], 'abstract': []}\n",
    "            node.i_in_doc[doc_id][doc_section].append(token.i)\n",
    "            node.idx_in_doc[doc_id][doc_section].append(token.idx)\n",
    "        node.is_end = True\n",
    "\n",
    "    def search(self, token: str, get_char_index: bool = False) -> Optional[\n",
    "        Dict[str, Dict[Literal['title', 'abstract'], List[int]]]]:\n",
    "        node = self\n",
    "        for char in token:\n",
    "            if char not in node.children:\n",
    "                return None\n",
    "            node = node.children[char]\n",
    "        if node.is_end:\n",
    "            if get_char_index:\n",
    "                return node.idx_in_doc\n",
    "            return node.i_in_doc\n",
    "        return None\n",
    "\n",
    "    def remove_document(self, doc_id: str):\n",
    "        if doc_id in self.i_in_doc:\n",
    "            del self.i_in_doc[doc_id]\n",
    "            del self.idx_in_doc[doc_id]\n",
    "        for child in self.children.values():\n",
    "            child.remove_document(doc_id)\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'children': {char: child.to_dict() for char, child in self.children.items()},\n",
    "            'i_in_doc': self.i_in_doc,\n",
    "            'idx_in_doc': self.idx_in_doc,\n",
    "            'is_end': self.is_end,\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: Dict):\n",
    "        node = cls()\n",
    "        node.children = {char: cls.from_dict(child) for char, child in data['children'].items()}\n",
    "        node.i_in_doc = data['i_in_doc']\n",
    "        node.idx_in_doc = data['idx_in_doc']\n",
    "        node.is_end = data['is_end']\n",
    "        return node"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 12 points\n",
    "\n",
    "def construct_positional_indexes(corpus: Corpus):\n",
    "    \"\"\"\n",
    "    Get processed data and insert words in that into a trie and construct postional_index and posting lists after wards.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus: Corpus\n",
    "        processed data \n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    docs: \n",
    "        list of docs with specificied id, title, abstract.\n",
    "    \"\"\"\n",
    "    trie = TrieNode()\n",
    "    for doc_id, doc in corpus.non_stop_documents.items():\n",
    "        for doc_section, tokens in doc.items():\n",
    "            for token in tokens:\n",
    "                trie.insert(doc_id, doc_section, token)\n",
    "    return trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "ai_bio_trie = construct_positional_indexes(ai_bio)\n",
    "# hw_sys_trie = construct_positional_indexes(hw_sys)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>مشاهده (۱ نمره)</b>\n",
    "    </h1>\n",
    "</font>\n",
    "<font face=\"XB Zar\" size=3>\n",
    "        این بخش برای مشاهده \n",
    "        posting list\n",
    "        یک کلمه و جایگاه‌های کلمه در هر بخش سند است.<br>\n",
    "         تابع\n",
    "        get_posting_list\n",
    "        با گرفتن\n",
    "        word\n",
    "        به عنوان کلمه ورودی، یک دیکشنری به عنوان خروجی بر می‌گرداند که کلید‌های دیکشنری شناسه سند‌هایی است که کلمه در آن وجود داشته‌است.\n",
    "            برای هر شناسه سند آمده در کلید‌های دیکشنری، یک دیکشنری به عنوان مقدار وجود خواهد داشت که کلید‌های آن می‌تواند \n",
    "        title\n",
    "        و\n",
    "        abstract\n",
    "        باشد که جایگاه‌های آمدن کلمه در بخش‌های عنوان و چکیده به صورت لیست به عنوان مقدار هر یک از این کلید‌ها می‌آید. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'b9b4e05faa194e5022edd9eb9dd07e3d675c2b36': {'title': [],\n  'abstract': [30, 60]},\n 'fc7c428f604d13604a1d62e8a3e1b393c730791a': {'title': [], 'abstract': [31]},\n '55f0b54f35949778487421325a1b6d0ba960b94b': {'title': [7], 'abstract': [13]},\n '4668306bc74576645c9cbe39a08f5f51a9bce4f4': {'title': [8], 'abstract': [80]},\n '8b9257f57d4aa43a5b1c7559a949e2cb7f9fd7de': {'title': [5], 'abstract': [68]},\n 'cd85a549add0c7c7def36aca29837efd24b24080': {'title': [5],\n  'abstract': [18, 87, 164, 194]},\n 'cd0d1ad3619e27311aeb07dd558904bb76cc321b': {'title': [13],\n  'abstract': [32, 55]},\n '353d401a96939ff6c5836289077663a1f868ab19': {'title': [3], 'abstract': [18]},\n 'b163c8bc2963c5f1146ec168d11f1ca55d1e5e1d': {'title': [6], 'abstract': []},\n '55ca7a2d71f7b82313b3a67d1713caad92a83ecb': {'title': [], 'abstract': [81]},\n 'f3d3bed63fb51315e2726837363ab3c9e89769eb': {'title': [],\n  'abstract': [0, 145]},\n 'a60680940d5486534b22ba2515eb8ae19dedf4f1': {'title': [2], 'abstract': []},\n '82a99e0d626847fadb6be938f979a4aec573e9a1': {'title': [4], 'abstract': [0]},\n '804f87743641b18ae9a917a84e434e2313859fd3': {'title': [], 'abstract': [35]},\n '1a3d3bc7950ee6a9734f41da6b41092d1eaf1984': {'title': [], 'abstract': [35]},\n '41a4ec2c2ac022d2d7791e717927e406c5bba4b4': {'title': [], 'abstract': [158]},\n '4fbe44946e0847ef82c86032840ad97b0521f40a': {'title': [1], 'abstract': []},\n 'e60ff004dde5c13ec53087872cfcdd12e85beb57': {'title': [1],\n  'abstract': [38, 41, 81, 96, 135, 161, 165]},\n '4c20e7f95448ca3c1042a6d7fa5fa15ec27e9aeb': {'title': [7], 'abstract': []},\n 'a2e667e4382aaa8e02a17d0522c1a910790ab65b': {'title': [0],\n  'abstract': [42, 79, 164]},\n '20c7aaaef3588cf16ba83e92075c9832cf3b6ac6': {'title': [],\n  'abstract': [0, 172]},\n '3f271912e46c926555a9078511ed681b58a5c27d': {'title': [0],\n  'abstract': [68, 136, 150]},\n '2f56d4ef0a9df1672699ecd787ffc9b3996026e2': {'title': [], 'abstract': [84]},\n '91e611c3e8705002438fb4439733e47ddec85b5d': {'title': [6],\n  'abstract': [3, 30, 89, 236]},\n '145da498aeef36e85b81807aeb8acf341a7fc28c': {'title': [], 'abstract': [137]},\n '9a293c0602bd93d8f2b922912a8189c5c04df262': {'title': [9], 'abstract': []},\n 'b32fb949edae3966fde7bc854099a659610ff14f': {'title': [10],\n  'abstract': [133]},\n 'a78ecfffe36114f1ccf69341e9949a9c407d3ea1': {'title': [0], 'abstract': []},\n 'c4d652597e9996d238524d3ecee7762750667ea2': {'title': [7],\n  'abstract': [70, 81, 129]},\n 'a0559ac561a6e816ee4294bf79797051281731ce': {'title': [0],\n  'abstract': [109, 113, 132, 191, 212]},\n 'ac03e40cc705cbd9270d221eb23cf06460be579e': {'title': [0], 'abstract': []},\n '6718e83fe2443acf30a1a9ee7b9accb540c77c28': {'title': [8], 'abstract': [83]},\n 'eb42cf88027de515750f230b23b1a057dc782108': {'title': [1], 'abstract': [148]},\n 'ed74b9390eda908060fa3501b8f20a836ec98d63': {'title': [],\n  'abstract': [125, 183]},\n '51847659fff3a746f86a169ec8efa855b6286ca6': {'title': [1],\n  'abstract': [63, 267]},\n '3aa681914a7da79f7d7293f51a058eefe61c8bb7': {'title': [], 'abstract': [154]},\n 'cb6a82115777edee8d72feeb77427265b2a48e27': {'title': [11],\n  'abstract': [82, 92, 121]},\n 'befe794c29e0fe10d836789b358c65b049435692': {'title': [], 'abstract': [133]},\n 'f3dabf05a64e2bd5c40c5cccd518646af7da891f': {'title': [3], 'abstract': []},\n 'e6c4293a92d50889eb202e49f85ef94dbb5f8afd': {'title': [14, 19],\n  'abstract': [24]},\n '0cbc480e0d380bbaa04bfb21a396c9e8da6e930e': {'title': [7],\n  'abstract': [44, 63, 68, 98, 138, 147]},\n 'ca1d0a2c8656cd013d411b24b7ee540821a938c1': {'title': [11], 'abstract': []},\n '883c5791a627d5bf679da1b5f871ff0d51792c6d': {'title': [],\n  'abstract': [29, 142, 177]},\n '25fcf6c8325a408c072f18f84c21c8b946408df3': {'title': [], 'abstract': [75]},\n '779b489971775507fe6a39d98c52c4df56d9cce1': {'title': [4], 'abstract': []},\n '4db22f69d5047659dc5f9c96be0b86a110bd4562': {'title': [], 'abstract': [6]},\n '492f26ecdab6a1f6665da64f861b0aedfc656d76': {'title': [], 'abstract': [63]},\n '2bcdc2897724e3bddf31c0fd1b9fb7799c3e2777': {'title': [], 'abstract': [78]},\n 'dc9c58793b1589132d49b0087fe493ff8e5863b7': {'title': [14], 'abstract': [10]},\n '2a793b8434174806bcfc3a367ad205613516818a': {'title': [1], 'abstract': []},\n '79fa1a2929a78fdfd4679fbcdeeb371b56b43084': {'title': [], 'abstract': [204]},\n '33526226231cce669317ece44e6af262b8395dd9': {'title': [], 'abstract': [0]},\n '35ead69983132d6efd7548788c66f355a5a9f9ab': {'title': [4], 'abstract': []},\n '0a78085721f70d82c1284c124c3137bb7c2b34e7': {'title': [6], 'abstract': []},\n '55e0b7cae68a817d91756d02c7eb04a7079d7b5a': {'title': [],\n  'abstract': [0, 52]},\n 'afff02fa27bdeb0e2dc658d1ce43af6d3f407ff5': {'title': [2],\n  'abstract': [86, 91, 123]},\n 'e0b8336be6987a469c02c545bcbd89b4221e21fb': {'title': [], 'abstract': [194]},\n 'bd36f1a9b111c535281c32ed600ddd6c4b71364e': {'title': [4],\n  'abstract': [82, 100, 185]},\n '0374f9e9541660a35881f0b09d5ee4c8eb5c921f': {'title': [8], 'abstract': []},\n '7f362f674869b1dc4c5bccde2c0e5ec4d9102c66': {'title': [], 'abstract': [197]},\n 'a664f7256ffb3b81bf8532f94d6d70122f303a96': {'title': [0],\n  'abstract': [116, 142]},\n 'bb4a9650ca3946c70a7e92007cc61dc0dfd75522': {'title': [], 'abstract': [48]},\n 'a389216b359c706418bf6611ef63bb083c15e9cb': {'title': [], 'abstract': [123]},\n '922d93d253fc8c55f559586a328ae999ef749cdd': {'title': [13], 'abstract': []},\n 'b3266cbc937ee738d0aed832888f81ff64761b72': {'title': [], 'abstract': [672]},\n '7afe3a449f0dd31ec08aa9748f94079684f899e6': {'title': [],\n  'abstract': [78, 128]},\n '1e58920c4235fdbfc22534c92938f22d1728f0b9': {'title': [0],\n  'abstract': [61, 166]},\n 'a7c3bdca5b1c2ca860a4d24d0b35f86b056bb30d': {'title': [], 'abstract': [163]},\n '11c0c566140dd607c1c4c8f86f14e3dd6c238c1f': {'title': [], 'abstract': [51]},\n '1ba07035f83792154e77ed35d842e04de8a1eeeb': {'title': [],\n  'abstract': [35, 49]},\n 'af24864ab4c654a44637098cb615c8b03f39b97f': {'title': [4], 'abstract': []},\n '8c69a38c303b7fbf64b6c7965f929f584bdfccd5': {'title': [0],\n  'abstract': [70, 95, 127, 147, 210, 225]},\n '261b15e8a013e07d6aaf80af930f4748ce35ca5f': {'title': [1], 'abstract': []},\n 'd29444b1873c206fba4ade481c33e9d80ecfb7c6': {'title': [0], 'abstract': [38]},\n '1a2b0383369172e08d91bc60fb70a9a988c317cc': {'title': [3], 'abstract': []},\n 'cc2defd5616b98eda74cb908d66498692753f164': {'title': [], 'abstract': [57]},\n '447499a1b18a71a914964f9bd782ac8cfbfcb739': {'title': [], 'abstract': [54]},\n '5fdb3533152f9862e3e4c2282cd5f1400af18956': {'title': [],\n  'abstract': [0, 155]},\n '2aac28eedb11ab7a15d2b095b276547fa03db580': {'title': [], 'abstract': [98]},\n '47eaa799a55efdb68c7a1ece2497d01bc0c0221e': {'title': [], 'abstract': [194]},\n '02da8e322c2b6fb00a6be642c61426c68e34349d': {'title': [0],\n  'abstract': [104, 190]},\n 'b2d1008ec02fc29478737daef710ba4436b5aafa': {'title': [9],\n  'abstract': [1, 17, 36, 60, 95, 125, 157, 212]},\n '5311c6e3e4a08bfec11a600888fa8537a9ee2e97': {'title': [0],\n  'abstract': [39, 76, 86]},\n 'c14e77fc10f133358903019f45132d694682ab88': {'title': [0],\n  'abstract': [12, 72]},\n '0f37b083cfd3d113f5c26dbb3620d246b9a40292': {'title': [12], 'abstract': []},\n '7db1e11805dc94b2c888625918f8ba810c4a7b33': {'title': [], 'abstract': [59]},\n '49e90a0110123d5644fb6840683e0a05d2f54371': {'title': [4],\n  'abstract': [101, 118]},\n '7b65f3e60065cff562f45c6c20f4e8a27949f18d': {'title': [0], 'abstract': []},\n '2e2b189f668cf2c06ebc44dc9b166648256cf457': {'title': [7],\n  'abstract': [7, 74]},\n '188452cb4bdfcf2b182c3eea6b2d3f15eb5ffa73': {'title': [],\n  'abstract': [32, 175]},\n '6c8a56ae495e5c8871061d1cd0f863d174f5e2ce': {'title': [], 'abstract': [24]},\n '2e535b8cd02c2f767670ba47a43ad449fa1faad7': {'title': [0],\n  'abstract': [39, 42, 72, 119]},\n 'a52d53f84400b10aee8d235d70852bc68ca0d32b': {'title': [],\n  'abstract': [31, 209]},\n '2515d60eadc7c4d56e463b2dcff6dd7a6de68fe1': {'title': [8], 'abstract': []},\n '5411a036cb5757915f2268333b6caf91132867ad': {'title': [], 'abstract': [12]},\n 'f98dbe64ed6fa8925048291fcceb625d704fb294': {'title': [], 'abstract': [35]},\n 'f31ff4fbf1582c090ec1ac247add43f8ff37a839': {'title': [0],\n  'abstract': [94, 207]},\n 'd034ad1daa31e05a10398fb41c4b3aa9a6eaf969': {'title': [], 'abstract': [194]},\n '96f535751c4e6e4fe5f2cb00d186fedbad7efd71': {'title': [1],\n  'abstract': [163, 177]},\n 'b0204e6c7301281ec8460e5251cd7c3c83c40883': {'title': [],\n  'abstract': [52, 191]},\n 'b7f993243d20310fc7eca06dc1cf0ce3550feae9': {'title': [], 'abstract': [109]},\n 'b0bf93b1ef16ace689123b26ffc7b17ac9894582': {'title': [11], 'abstract': []},\n '10fe7a767dbcff9e68579bfb8fb16638d7d465fc': {'title': [],\n  'abstract': [41, 137]},\n '0b26e182cde3c28d79119424660d05520428ec8d': {'title': [], 'abstract': [3]},\n 'fe0776a8ec8d0d1146f3c6d90d3f76d8e443f695': {'title': [7], 'abstract': []},\n '5eee61e47d55ed1ba90a00c91fcb3673d91e042f': {'title': [], 'abstract': [80]},\n '7d8d989194afb78158206b9803907e2c0bd228bb': {'title': [], 'abstract': [153]},\n 'd602137d38d4fad9e6db07d911fbf3551894d441': {'title': [0], 'abstract': [0]},\n '117ac7c5d42bfdbe83432672db05a2de08dae113': {'title': [], 'abstract': [1]},\n 'bf05819fa9366b3b67b0d86347b7b16fee88eb61': {'title': [], 'abstract': [1]},\n '0f6894b547489e1b07d0c4783947b814ac846a17': {'title': [], 'abstract': [56]},\n '79cc853e623ef1ae6bef9219b4d8900be7b5d917': {'title': [],\n  'abstract': [54, 173]},\n 'e036d15bbb4cc3176b07e2cbfe842165ee841a26': {'title': [], 'abstract': [0]},\n '1de7d838cfce1c3bef65b134bae3d00b59eddd71': {'title': [0, 8], 'abstract': []},\n '2abde28f75a9135c8ed7c50ea16b7b9e49da0c09': {'title': [3], 'abstract': []},\n 'da26630c9d931952f1d68308148f1289f5332607': {'title': [12], 'abstract': [11]},\n '0695280cb4fdeb4eb8c0b01dd04a3a5f3bc6ef56': {'title': [4],\n  'abstract': [6, 59]},\n '60d55fcfa445184f6b2c711138899b7c2114a94e': {'title': [], 'abstract': [77]},\n '245eacda2e4cbac0b8157bc274d2417aec0da13c': {'title': [0], 'abstract': []},\n '1d3485be8a6ca0ce83f2c9e968547cfc24240ed3': {'title': [11], 'abstract': [15]},\n 'e10a130ac1404572b9cba1d636b34169799ecbcb': {'title': [], 'abstract': [86]},\n 'fc8f2264c67107fe3ae5c084d436075afe6486b8': {'title': [9], 'abstract': []},\n '284f596e438da346acec45b59d4c10850632ed66': {'title': [0], 'abstract': []},\n '52ce982e6d5cfe6e49bd451ef5617b348a2a4814': {'title': [], 'abstract': [78]},\n '335cce41a59ff311213da55dfcd116aefb97fdb8': {'title': [4], 'abstract': []},\n '527fc9235ebe59f415af8af1aba3db4325be1597': {'title': [0], 'abstract': []},\n '60c34a1ae08aefec26d2a1fbcf5b333a1de9a7ee': {'title': [], 'abstract': [158]},\n '821f2cae0304cd3714ebd7ca31fa68d4029f1d3c': {'title': [], 'abstract': [58]},\n '763be1dffc2aec2637ebea505a7612bb6843521e': {'title': [], 'abstract': [1]},\n 'b4a4e6fe63426b9fb4393c939792da8e7c4a1a59': {'title': [], 'abstract': [117]},\n 'f505853ee5d63df2c95919b3e01be258d313c4aa': {'title': [], 'abstract': [22]},\n 'edacb19ef8c6ba532639b587904f67e648910f47': {'title': [6], 'abstract': []},\n '3e6c84302b2b56cf8369253d6168b852d0aa1fd6': {'title': [0], 'abstract': [186]},\n 'f86bbcff0d2cdcf52049373bf1b67b0d4b6d3e7e': {'title': [4], 'abstract': [22]},\n '360e574d95ea8d5e3938f756badd1d5993974159': {'title': [], 'abstract': [71]},\n '96c62b83c2dc54b22a126b53efb201fae61b3983': {'title': [4], 'abstract': [4]},\n '04625f7a0f84f0466f690d7b0bc672c7c90c193f': {'title': [],\n  'abstract': [49, 56]},\n '4c8f50cde3f2ce221e3c6d5171420b96c144df27': {'title': [],\n  'abstract': [9, 44]},\n 'bfe284e4338e62f0a61bb33398353efd687f206f': {'title': [], 'abstract': [64]},\n '8f1a8b82c7be223f195b4f03ffa1943391fd428b': {'title': [],\n  'abstract': [17, 46, 174]},\n 'e2c477de72bb7718f5304c6f38457fda9c8334b1': {'title': [0], 'abstract': [7]},\n '9c1bcf9e1aa2c5b8b3255b84fcce8d6bb10ac397': {'title': [],\n  'abstract': [102, 465]},\n 'e56b10f7cd4bf037beac84da5925dc4544fab974': {'title': [], 'abstract': [3]},\n 'ca120273f3cd35d565ef3d9afdcec80adef19d37': {'title': [1],\n  'abstract': [45, 143]},\n 'c6812c3dd1db1d3fb204296af79c22dcac9964c7': {'title': [], 'abstract': [225]},\n '4054f15b807dcdc4d2112166f449d70ab7b1a8da': {'title': [],\n  'abstract': [44, 183]},\n 'f215ce917c06fcfb21af5cc0283e008e6c391816': {'title': [], 'abstract': [157]},\n '1a442ec8ba0235c7180b29c39a507ee57841fd7b': {'title': [], 'abstract': [13]},\n '7ac13836ed80c668eff5ac12903a0cd5c237e27b': {'title': [1], 'abstract': []},\n '14b8737bd7870fc61346123fffc9755bce7254fd': {'title': [], 'abstract': [5]},\n '441ff323c92331e655ce9ff896773fc00b55089a': {'title': [4], 'abstract': []},\n '276f151c8e2eaf17541966c49c0aabc96db8f64d': {'title': [], 'abstract': [9]},\n 'f9c7fc60267d9541fa396e2ba63ad78a2dd995eb': {'title': [], 'abstract': [171]},\n 'e58869795a355efe76491ca8a619bf87b233a0fe': {'title': [], 'abstract': [211]},\n 'a93aaf608f3bccb8174cd52ff32dcd9ffb25b423': {'title': [2], 'abstract': []},\n '54e446b333dff04daf7edeaa4e944c7e28533ed3': {'title': [17], 'abstract': []},\n 'b2c1fb445d25de3a26482440cd4f977e2f1cde46': {'title': [5],\n  'abstract': [68, 97, 139]},\n '64b9be00f4eecd465b4e8e46e2ab7624d7eaeb2b': {'title': [],\n  'abstract': [57, 110, 180]},\n '5d7cf0d50d5fd373bafef6e3ab554936a54e3cda': {'title': [], 'abstract': [25]},\n '0276aecb97ffa1f7f279e2768abb3484933eacfb': {'title': [], 'abstract': [30]},\n '13111b3795bf32fc1ba508e6ea615031751b33ee': {'title': [], 'abstract': [110]},\n '367f2c63a6f6a10b3b64b8729d601e69337ee3cc': {'title': [],\n  'abstract': [0, 50, 134]},\n '531909281a0c92c738d9abfe7ad9a3630f9a2caf': {'title': [], 'abstract': [119]},\n 'c827842512a843ae3d27db554b954a4f782a633a': {'title': [],\n  'abstract': [30, 113, 159]},\n '713e881b5c3134debf934026edf6f0ba3cb42c3c': {'title': [], 'abstract': [88]},\n '011a1bbb4059b703d9b366468ef9effdb49f4df9': {'title': [], 'abstract': [248]},\n '0fc190033ec2832ed65dfac7a19bdb8a270fb6eb': {'title': [], 'abstract': [12]},\n 'b8c6fccfd7190cdca8647f5886716a4f56d9de4b': {'title': [],\n  'abstract': [0, 23, 55]},\n '8336e55d4b31a4ba6c3a128d46eb0289aab19789': {'title': [], 'abstract': [152]},\n 'a4040560bed2818f9e64293c462627858d99cf3e': {'title': [], 'abstract': [124]},\n '96baf66b1ead911d18b64ad674c9512e189c290b': {'title': [3], 'abstract': []},\n '40cec58d760940f62975e0d5e99632e28df0b5d0': {'title': [5], 'abstract': [44]},\n '1e8a5d2c359ead7ab2e55e1d492a7ed1e2808d0c': {'title': [0],\n  'abstract': [25, 53, 67, 105]},\n '3cf6300ea6f90876b14dc56242cf57ce0d36d8b5': {'title': [8], 'abstract': [85]},\n 'b5b7757491d8f60eb68e9b5f64190443cdcf55f8': {'title': [], 'abstract': [122]},\n '6b2062812d2e353ea884a0cc077e9f6c73351423': {'title': [], 'abstract': [0]},\n 'a1de21ce6dd0ff6327e6cf5f124cce8db197991f': {'title': [5],\n  'abstract': [123, 135, 180, 219]},\n '13c2abd38e3f9f5d3eeab177d43a1e0e1a6e64e8': {'title': [], 'abstract': [28]},\n 'e157466239e336a3146086a91da58a7938de977e': {'title': [10], 'abstract': []},\n '39c5740304b5f4072f92e4e012a4b57e7bc2e817': {'title': [], 'abstract': [16]},\n 'f6a80bfb5fb23fdd940f1bf36ada123248346ade': {'title': [], 'abstract': [142]},\n '8eba733040b016e9c7ec5c3dc87cc1b28a5c2000': {'title': [2], 'abstract': []},\n '46917e427a7aa1f4d415f8620c43ba4845efd435': {'title': [], 'abstract': [81]},\n '9cba6d03d13e18c0100ad9e7858eaa0ec2d18ee1': {'title': [], 'abstract': [0]},\n 'b9e98f630e8eaf77ddcd0f80d1360b611ae61e70': {'title': [0], 'abstract': [19]},\n '3d5a4ac2982fea9b2a675916639c9e892a89a628': {'title': [9], 'abstract': []},\n '0ea4076406bdef0225d095b45d20ee457a637eb9': {'title': [2], 'abstract': []},\n '1b0cbf49580883157dc2e674e64270b16656aed3': {'title': [], 'abstract': [0]},\n '3ab03674dfbb3762ccf3f842e840ad25ddb79be3': {'title': [5], 'abstract': [0]},\n 'bd25bbec1c321ab28846b04ee6d269e10e18f54b': {'title': [], 'abstract': [265]},\n 'c5adb029d021946dc4347277f8d43fe509cb96b0': {'title': [25], 'abstract': []},\n 'e091a2127313fa6ef23259144b72eebec2b08d14': {'title': [], 'abstract': [70]},\n 'a2843523d5b96c380220ce1d6da133abeabcfe30': {'title': [], 'abstract': [115]},\n '3b0fb765716ef6861a84abffcbe40643857c613b': {'title': [], 'abstract': [4]},\n '255782ed38a221a43ddb5e8c63e8c77bf26382e7': {'title': [2], 'abstract': []},\n '5e159c0f1f56ebc51e8d44c18cf579a891ef1c5f': {'title': [1],\n  'abstract': [56, 97]},\n 'e97b7881b97902475a5ac04d5698f34ae047a164': {'title': [], 'abstract': [50]},\n '72cc043fd66ba56461a12db30d60f19ea216ff4e': {'title': [], 'abstract': [118]},\n '6c86d3a9c66ebc5112f6e1a3534f2070a834de5f': {'title': [], 'abstract': [284]},\n '81a4fd3004df0eb05d6c1cef96ad33d5407820df': {'title': [],\n  'abstract': [0, 94]},\n 'ab6d2e28f51012b1968b8b460624178d1cf47a5f': {'title': [5],\n  'abstract': [20, 61]},\n '8d3e9f744ee2514eac27d9288581ba4cab131f4a': {'title': [0], 'abstract': [122]},\n '498e003901f8287e89e5064477cd22dd47e49d61': {'title': [5],\n  'abstract': [8, 164]},\n '80be914311228dc3065f2f75f3de71459f3b1043': {'title': [0], 'abstract': [90]},\n '3060a4828f4fd0a89e934db5b74bfdef95141d80': {'title': [8], 'abstract': []},\n 'ccd8d46f4c5e59fba944385ad34ef96de950582f': {'title': [6],\n  'abstract': [35, 89, 105, 135]},\n '4a8cdb0175b37e13de8bc64cf32b9e784aa0808c': {'title': [],\n  'abstract': [34, 165]},\n '1e70d24649c5572b03ebbac45a784bf7698e56c7': {'title': [4], 'abstract': []},\n '6d4a87759917132913319960389f17fa1fe8b630': {'title': [],\n  'abstract': [8, 147]},\n '11b64286259c92cc82ef2ccc05c492f1a84ece82': {'title': [1], 'abstract': []},\n '59d8c68de09da69a608ceb149f40114f5538c5b1': {'title': [], 'abstract': [52]},\n '2c88c3d8bc68858e4c9ba58ec3d71454e94eb96e': {'title': [8],\n  'abstract': [77, 276, 313]},\n 'b8292eff779c3e00d96a5f893fbc9008793f6434': {'title': [], 'abstract': [86]},\n '832c0fb24669a7f7502510a70c4f3ddca42d45f9': {'title': [], 'abstract': [306]},\n '51ba3b33f445199d9f3cddb5b00c7e2927199b0c': {'title': [0],\n  'abstract': [2, 98]},\n 'a52a3aac68f4fd67b67ccf6839765403a101f681': {'title': [6], 'abstract': [12]},\n '0c2a4ee3e6b8cf1485fb1ffee00dd4f5a9fc4bef': {'title': [], 'abstract': [261]},\n '21117380118ddce47b3c515c5228372c513e61ba': {'title': [0], 'abstract': []},\n '6c96c2d4a3fbd572fef2d59cb856521ee1746789': {'title': [],\n  'abstract': [3, 63, 267, 284]},\n 'd5ce8f2c3c4be1fbae610a4b81eee85c41337150': {'title': [0],\n  'abstract': [88, 117, 132, 181]},\n 'ab096e819b0fcb82edea56b9d28fd5500c16906b': {'title': [0], 'abstract': []},\n '3937f1ad451462fbd9994c37ad22af841be9a3f8': {'title': [],\n  'abstract': [68, 106]},\n 'e3c7766bfb93a488218ff98d7420dc20cead969d': {'title': [], 'abstract': [7]},\n '2867f915f7419915909e60b3f9f8a29ada9f10d2': {'title': [7], 'abstract': [80]},\n 'e56320ed18e4fef4cbec9a35a1d5e7fe9c05b7fb': {'title': [], 'abstract': [20]},\n 'f3f1ea39c55e9c85a68fe50450cd7dfa6515e55c': {'title': [0],\n  'abstract': [87, 117]},\n 'f9ad25505d7b491b2d14d4178fbbe95ecc0c951f': {'title': [], 'abstract': [24]},\n '924385a663f9bc3a5f6979f72b43e069e06c263c': {'title': [4],\n  'abstract': [6, 57, 81, 90, 122]},\n '8d35663a80199b173d8cbd12dbf2300a9f86a021': {'title': [7], 'abstract': []},\n 'd5d571db338064b050044f936ff6914c79c5e4a0': {'title': [0], 'abstract': []},\n 'b6721d9173ad140c77cdf98a919bdb40baf42c0c': {'title': [], 'abstract': [96]},\n '7d8d6d30ce3bd383f947d6d88e22e00e809065f7': {'title': [5], 'abstract': []},\n '802168a81571dde28f5ddb94d84677bc007afa7b': {'title': [7], 'abstract': [0]},\n '01c0348a895d87aaad05b7705a62478f45b70449': {'title': [1], 'abstract': []},\n 'a22ee3256e28c7551d2fd7aedb965760457e8e6a': {'title': [], 'abstract': [36]},\n 'f3dc56a28ef71987f3999ba157f91cf351fb0a5b': {'title': [3], 'abstract': []},\n 'bab1a7f7dedcbcf0d3e918c8ab548f56374f7243': {'title': [10], 'abstract': []},\n 'ef8ab2a0be51a0cd04c2c0f01adfae956a2a84af': {'title': [4], 'abstract': []},\n 'b9046042830f6906c2db1d6c31cc1f8c10348fc0': {'title': [], 'abstract': [177]},\n 'f44f5a877b34788afb3e0fc49c634faff69ab152': {'title': [],\n  'abstract': [124, 178]},\n '6d8052588c62e5bf2a073ae414867a78784ff663': {'title': [3], 'abstract': []},\n '3c6599052623542f6e21a2cc45a6fde4fb2dc374': {'title': [],\n  'abstract': [51, 145]},\n '25e9fa483a048607131a5a0e3287e8f457fb4807': {'title': [],\n  'abstract': [0, 22]},\n '82b1b54e0b6134c4f072d2fee9692f3fd636dfa2': {'title': [], 'abstract': [54]},\n 'b71cbb8150760e1724a9c5dec78af4d0832e4236': {'title': [7], 'abstract': []},\n '505e72b8d60e987e89b93fdd98859b857ca94207': {'title': [1], 'abstract': []},\n 'f08c5a30f1f0c9d79861f7eb993bf89fa9ef1074': {'title': [1], 'abstract': []},\n 'af5e811897a5ab945d58624d576debd82e03fac3': {'title': [], 'abstract': [2]},\n '6705972cf9104d76fd7423dc414f3915f41ae783': {'title': [10],\n  'abstract': [216]},\n 'bbf052271c70dd926cd230bb5640cdcdfeccf1cc': {'title': [], 'abstract': [23]},\n '6bd36e9fd0ef20a3074e1430a6cc601e6d407fc3': {'title': [0, 2],\n  'abstract': [163]},\n 'd05ff914131723b3287b91c169d579f13fd01209': {'title': [6], 'abstract': []},\n '74ec403743704c1d72b83c96d422996bcf232b1f': {'title': [], 'abstract': [53]},\n '901d678c367247e84b39a9ae5f913c5fbd958a0e': {'title': [3], 'abstract': []},\n '08d0ea90b53aba0008d25811268fe46562cfb38c': {'title': [5],\n  'abstract': [0, 188]},\n 'a469cb515cd9a2e1923a7a9b3b3fca3690881b19': {'title': [2], 'abstract': [110]},\n '28960bae9bbae36e25d1018ab7d6e8b258a903a0': {'title': [8],\n  'abstract': [35, 67, 141]},\n 'a11124688cdcee011043d7e4cdaf10332a533946': {'title': [],\n  'abstract': [20, 178]},\n 'aac329026fb5f08f54b9f06f35ea2e0c3b664a76': {'title': [], 'abstract': [198]},\n '424561d8585ff8ebce7d5d07de8dbf7aae5e7270': {'title': [], 'abstract': [174]},\n 'd451901a6a12c61179289cac7a4588a86c234112': {'title': [], 'abstract': [159]},\n 'f29df408f1407c60b0f85dd595a883de7c66e763': {'title': [8], 'abstract': [70]},\n '4f8bf7de1d0632ebc5e9d5a1da14c63ad3b7124f': {'title': [2],\n  'abstract': [23, 106, 126, 202]},\n 'a06a8ca70096e567e5cf1e433cc99ac1d519c4d0': {'title': [],\n  'abstract': [27, 67, 85, 102, 152, 171, 201]},\n '5d68bbeb2d293cbda75994ca5040fd083665e82e': {'title': [1],\n  'abstract': [98, 118, 170]},\n '27eec716b3d5f2253ced3d6a30eaaa5558ae94d6': {'title': [], 'abstract': [176]},\n '5bdbadc741ce13762b7c914c1514124404c46211': {'title': [], 'abstract': [200]},\n '1cecbb9400b0d8b4342e6c25599b0e6a53a0ed41': {'title': [0], 'abstract': []},\n '5f58c4eef5728d53d124de6226c134d2e28d846c': {'title': [0], 'abstract': [10]},\n '939f575c8669331ce29f8ba4415dc2ddd06d5a5c': {'title': [1], 'abstract': []},\n '8275caf3674a37343fc6486ec354f0ebdf44cd99': {'title': [],\n  'abstract': [22, 35]},\n '08f2d3b5a393d9b7aa47a5edf81d6f8604688e07': {'title': [],\n  'abstract': [72, 79]},\n '3ef82c1cf7af5988afd6ee19cd595556e0085a76': {'title': [],\n  'abstract': [16, 32, 66]},\n 'd939289250e4c635ae2d3e80834862d392473100': {'title': [5], 'abstract': []},\n '7dbc187624870198c9713483a3d225be22fb3fe8': {'title': [], 'abstract': [197]},\n '20f77d34ab1aec7d0a6e613a740aff7ec7fbf55a': {'title': [8], 'abstract': [62]},\n 'daf74c34f7da0695b154f645c8b78a7397a98f16': {'title': [3],\n  'abstract': [22, 60]},\n 'e38e70580acb204c05096de8da90b7ab1d4bdb6b': {'title': [], 'abstract': [46]},\n 'e503e08d63ee02fd83f549bdd9ddc8b58d5998df': {'title': [], 'abstract': [65]},\n 'd716435f0cb0cac56237f74b1ced940aabce6a2b': {'title': [],\n  'abstract': [18, 83, 138, 224]},\n '80028a3e9e8712d3cfe79d3c092a91c209a8cc4d': {'title': [], 'abstract': [55]},\n '9702b3da2cca9b9f9ca53c0be1de09b644a9e34f': {'title': [8], 'abstract': []},\n '9fd8e5cb7958c1b005096e95ba15d0d92cdfbbaa': {'title': [], 'abstract': [22]},\n '6ff5533db1ae20f72f471b97965a8b67f05e62b6': {'title': [],\n  'abstract': [179, 254, 269]},\n '5c6199859eb8b4ebd4188c6587f6ad8e6448a983': {'title': [14], 'abstract': [46]},\n '602645d132457923c98794db8f6d4a042714620e': {'title': [],\n  'abstract': [2, 67]},\n '7e1b5de9e0a8767a3d4071ea1299358dc067f7e3': {'title': [], 'abstract': [230]},\n '24cf86a418c9471e8001961c87697c825f0bba8f': {'title': [],\n  'abstract': [13, 126]},\n '3e0cb50eb39ec30c9a791bf2fc4a7878d0a2478b': {'title': [], 'abstract': [149]},\n '930a3aabbaf3476807dd0fa0cd2830e371cb5b1c': {'title': [0], 'abstract': []},\n '56c6cc360cc60f20884851daa8943d16219fb5c2': {'title': [4], 'abstract': [128]},\n '6837d09722a991a433604818ad83b36337ec1940': {'title': [], 'abstract': [70]},\n '36dc816c0313d1ed1be6ee5effebe08f92a41836': {'title': [0], 'abstract': []},\n '5efe15ac1bd81a9d80746e0f0325b15854222353': {'title': [], 'abstract': [101]},\n 'b4d612f602817f4a7d1ea33d7b03253394cf5cb3': {'title': [2],\n  'abstract': [26, 170, 197, 221]},\n '625c3decc31a2c3d7ca9f5f84450f701798c28ac': {'title': [], 'abstract': [141]},\n 'd19701ccfb9170cc4b8b7856ba186ed3db7eb56d': {'title': [4],\n  'abstract': [171, 205]},\n '34ee498a8dab7d786ff8ae1b648cfcfdb12fcf16': {'title': [12],\n  'abstract': [115, 135]},\n '84b798942b11905c1d9190d54ce7c28f12e6c2fe': {'title': [], 'abstract': [316]},\n 'f374d4bdf63fa1d2358a5559dbea32b576968d5c': {'title': [], 'abstract': [3]},\n '4ca058c44bc35930b2a3cef88018f49336392bd6': {'title': [2],\n  'abstract': [119, 145]},\n 'b0c065cd43aa7280e766b5dcbcc7e26abce59330': {'title': [3],\n  'abstract': [6, 187]},\n '590d4a5e92d9f00621aec16fcb5df16d1912b4ec': {'title': [2],\n  'abstract': [4, 85, 147]},\n 'fd81880d09fa9997be8a0fccd5f1bf3fc4eb3fcb': {'title': [13], 'abstract': []},\n '2a48d2b673689e4434fc6b86965ca2a91bb40103': {'title': [], 'abstract': [17]},\n 'fef2135b3ae7b27ab28ddf41a943bd2ddc5d5113': {'title': [], 'abstract': [89]},\n 'eab422b69605e047597a743ebb657b2728ad7f8e': {'title': [10], 'abstract': [27]},\n '6c30e84311d6ed8a41908bd4ce0ebd7bcc08cc83': {'title': [], 'abstract': [75]},\n 'ddf52ceb8452344f4b93c87c0ec97834cbdd7230': {'title': [11],\n  'abstract': [67, 89, 95, 150, 397, 532, 550]},\n '42488e3a61d577e544e554b206a17e408f4cd765': {'title': [], 'abstract': [53]},\n '67c4528de75ae743d23a4eea5c03316a7a8cf9d1': {'title': [], 'abstract': [111]},\n 'ede7829b3f057a874c513919d19307e2b60ead23': {'title': [], 'abstract': [111]},\n '8381157eae4fbf8908d0312a9642f8e69e944449': {'title': [],\n  'abstract': [76, 97, 128]},\n '76b1768c4185b4b6e525e797be137964ffd46cd5': {'title': [], 'abstract': [50]},\n '4acde8d06cb9d7db0a793169d2bfe007fcd62301': {'title': [3], 'abstract': [80]},\n '2c03df8b48bf3fa39054345bafabfeff15bfd11d': {'title': [0],\n  'abstract': [0, 24, 94, 167, 184]},\n '1a3c74c7b11ad5635570932577cdde2a3f7a6a5c': {'title': [1],\n  'abstract': [5, 34, 101, 179]},\n '88e8db0971a8390d4b197e44242e87c50ef3e1e1': {'title': [2],\n  'abstract': [51, 74, 137, 270]},\n '3b9dfcde5235f66a3657f54a93e189f620ff9436': {'title': [], 'abstract': [227]},\n '30b25894928fa69b748fe504e37ce3656ff5d71b': {'title': [3],\n  'abstract': [173, 201, 237]},\n 'dd8ae7e8b72b0bbb11a4d9537a0f1b9f051b0793': {'title': [],\n  'abstract': [40, 171]},\n '1f83ce6b690b452d0b03ef6e4b43e96ff9ee6d2a': {'title': [3], 'abstract': []},\n '2faf72ee3ff950009a10020f720db336bf5e63a0': {'title': [], 'abstract': [3]},\n '98d2656eb36056a81462ad175656a8e8730bf13f': {'title': [10], 'abstract': []},\n 'dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4': {'title': [],\n  'abstract': [76, 81]},\n '5e785ebb971ef0c908ac4e408206e82e76388cbf': {'title': [],\n  'abstract': [35, 50, 70, 93, 101, 116, 138]},\n 'aa14c359aada2ce633f794ddc40b584ece79ddf5': {'title': [19], 'abstract': []},\n 'ceee1196f166a41c3c6cbccd03a9e6b8a9bfa574': {'title': [9],\n  'abstract': [24, 103]},\n '25e3cad9f9f7191e5057975c9c2d3f2fda24ff96': {'title': [5],\n  'abstract': [18, 60]},\n '285018adc33d8b2735dc2bb918f9ef8bae36ba25': {'title': [],\n  'abstract': [37, 126]},\n 'ef2e936aa7b6615f5e7cdb642428da5defb57c07': {'title': [],\n  'abstract': [0, 17, 178]},\n 'f508919ebbf44b250159e9c97f749610a5ae670a': {'title': [0],\n  'abstract': [47, 138, 147]},\n '28227bc2f709616b606e10f72748a03cfc47cdbd': {'title': [], 'abstract': [136]},\n 'f08f76b54c1b6ac1c760f0d9389e6eeb1ce8204a': {'title': [11],\n  'abstract': [51, 142]},\n '9a3855ac64358d95386cac5120929c88197e26dc': {'title': [], 'abstract': [190]},\n 'be12d320fdfa1319a8a8379b9e637ffbb6450f97': {'title': [], 'abstract': [142]},\n '17af9510a38e4dec93398707f11d833c8af36254': {'title': [], 'abstract': [10]},\n '77d30cf9a34fb6b50979c6a68863099da9a060ad': {'title': [],\n  'abstract': [70, 111]},\n '7efb4f8ff9aa6f5e9691e9392b539298ef46ca04': {'title': [3], 'abstract': []},\n '9f25e139d99cac8957c758325bf77dad29d65073': {'title': [10],\n  'abstract': [13, 148]},\n 'a2b231bc08cf3d9ed66eb60e6e45a0d84e94c090': {'title': [3],\n  'abstract': [8, 57, 78]},\n 'bb51ca71833d42fa58f9adccb2296bdf665cc158': {'title': [11], 'abstract': [30]},\n '642d0f49b7826adcf986616f4af77e736229990f': {'title': [0, 4],\n  'abstract': [31]},\n 'aedbb2a8c27d1460345df0dcdfdc1f21e2225815': {'title': [1],\n  'abstract': [10, 85]},\n '28293e2b07acccc222f5b0deca15105430759a92': {'title': [5], 'abstract': [50]},\n '4dfbc372c5e127abe7989e9c4ef75daac7370cd2': {'title': [8], 'abstract': []},\n 'dfc66a53c836846d524765f44e111c94ebd2ad37': {'title': [], 'abstract': [156]},\n '8edb469ef694e6259a97e88a53440338d3865ebc': {'title': [],\n  'abstract': [5, 133]},\n 'f9c16fca2662a82428a977e09db0ea02a74911da': {'title': [6],\n  'abstract': [69, 79]},\n '742c3acf2dab95cabaca8bd8aa27dcc03863ac2b': {'title': [], 'abstract': [31]},\n '85a854a51833b16994f5af77a7419acb2bc78942': {'title': [], 'abstract': [70]},\n '5cd20c68a8c8554b89f762e0a5eac2bda03059c4': {'title': [], 'abstract': [0]},\n '29edf1f3bf744aa1a1b7bea3c1fb455bad8fc898': {'title': [], 'abstract': [15]},\n '263d9163626aebc22c9bb45aa8269f18a58dab91': {'title': [], 'abstract': [213]},\n '8407167036a2795944138ac909e16adadec13668': {'title': [], 'abstract': [20]},\n '0c35fd52b312eb3881a08b04b67b4b25f473ab8e': {'title': [], 'abstract': [112]},\n '53b047e503f4c24602f376a774d653f7ed56c024': {'title': [],\n  'abstract': [9, 188]},\n '5a7033e9f2c459a9162e16d607297d88c60f5236': {'title': [8],\n  'abstract': [77, 87]},\n '9358d9e9afbc1eaf6b2f2042a8adc573556f566e': {'title': [3], 'abstract': [133]},\n '1167a9431e3743e16ab7e38bf60bdf63a278f7e9': {'title': [8],\n  'abstract': [40, 121, 156]},\n '64d4fcefa471fba93b910480c69f0127895b3512': {'title': [], 'abstract': [52]},\n '8d68eae4068fca5ae3e9660c2a87857c89d30f73': {'title': [], 'abstract': [0]},\n '4948596c4cb32a6ce1ce403a580c7fc4a51fe4f7': {'title': [0], 'abstract': []},\n '549cc49a43feaae4bc64da81e7299f0a78e6858b': {'title': [1], 'abstract': []},\n '82e597010ee1bede0b50f7ff8c6a249eba3a67a8': {'title': [], 'abstract': [4]},\n '6a51ddf8788de3002ec15ca7b30d2195c08c8929': {'title': [],\n  'abstract': [0, 36]},\n '89890e89a1ced045193fff89f005cd7cafa76d9c': {'title': [], 'abstract': [23]},\n '3dda2a28f8b7ddb89bfaa3bf1f1577d30afc7f2a': {'title': [4], 'abstract': [16]},\n 'b4919d8160d1c5b47f0ecbe30fa2237fecc7ba25': {'title': [6],\n  'abstract': [88, 125]},\n '1a9314776fbf9dd92649be5c2583b7ff92d79b56': {'title': [0], 'abstract': []},\n 'e44ef7be16ac01dfde6597b094bcbe4f81f771be': {'title': [], 'abstract': [59]},\n 'b4a94f4bd9842fbb72dc491665cbe70316aba431': {'title': [],\n  'abstract': [19, 98]},\n '796ca5c0c43614a94167fd48279bb9c6eaef49e6': {'title': [8], 'abstract': []},\n '028b15f4e4e6e12ab48385cd274cecaf887e80f5': {'title': [], 'abstract': [247]},\n '3a7f661d157cfb689bb35969e1a0fccccf8ba698': {'title': [10],\n  'abstract': [41, 169, 189]},\n '601106659dc89cb329e8a045ef6ef288fe37b0dd': {'title': [],\n  'abstract': [12, 195]},\n '7a0324f4a44047260ab3ebbd87a3f4744f1ea945': {'title': [], 'abstract': [10]},\n 'fef6f1e04fa64f2f26ac9f01cd143dd19e549790': {'title': [], 'abstract': [74]},\n 'c003e6f75f9067a33d4cc1da033cfb3f04964a6c': {'title': [4], 'abstract': []},\n '1b277f6e55e328c865c83518594fe3b5bd569205': {'title': [],\n  'abstract': [43, 73]},\n '2d55e2506203449d17f5f6f33a00c6faed66f563': {'title': [5], 'abstract': []},\n 'af3b7e1e2921aa68f6e00e07589c0d0f585e9f76': {'title': [7], 'abstract': []},\n 'b3ea79473e7438ae3d551f79a84207f8bd0e830d': {'title': [5], 'abstract': [65]},\n '6dc580ca568e8685854e4229881d74c69d57c8eb': {'title': [15], 'abstract': []},\n '27b6749039e79be9357356f3abe232dc645b6623': {'title': [],\n  'abstract': [4, 151]},\n 'b051f7540ca1c2c5d1f8e6eb9ada449d2933ac45': {'title': [], 'abstract': [0]},\n '14a657db8a4e95e07379494828717027965022dc': {'title': [5], 'abstract': [150]},\n '6541eba27e35e43c009cf775df96b679eaf49692': {'title': [], 'abstract': [8]},\n '3fcbf108daffa73ccdead58ff7662d6f241339de': {'title': [5], 'abstract': []},\n 'd2e4587744a89bad95fea69e08842cad6c8ff0dd': {'title': [], 'abstract': [13]},\n '8df989b1640e841538f8a12cc973b565b0712757': {'title': [4], 'abstract': []},\n '857e2a687bea7e985287118f68cc2f702eb7f75a': {'title': [], 'abstract': [89]},\n '877150193febd35691287324bb7c436fd8d75acf': {'title': [], 'abstract': [33]},\n 'b64a9491b5f64e68a5c48963feff50417510c799': {'title': [3], 'abstract': []},\n '13103b3bd4808ffd8dc46c6a77cec376eb401736': {'title': [], 'abstract': [52]},\n '20484b42bd462ef016de99ffa71f67c6c295ed8a': {'title': [13], 'abstract': []},\n '05a230ed244e2d262f54a2a8509dd5b7aabdeab2': {'title': [1],\n  'abstract': [124, 217]},\n 'efb4154ceb89c700a011923b9dfe492fca30fb62': {'title': [], 'abstract': [65]},\n '7494f7fd1cd30ca2a2753b69271ed75b3967cb70': {'title': [7], 'abstract': []},\n '1cae417456711c4da184f5efcd1b7464a7a0661a': {'title': [], 'abstract': [97]},\n 'd14ac2acf1b18e815385c631216eb4ee3a4fc842': {'title': [],\n  'abstract': [516, 522]},\n '469636449a996299e43176a6ecca36dcbbb9e669': {'title': [2], 'abstract': [52]},\n '9f32597531302a2a3404ee3c75d63f0fc8c05b50': {'title': [],\n  'abstract': [5, 81]},\n '1ac0ab5919725fb535b96a97fec42a027ddab54e': {'title': [7], 'abstract': []},\n 'a5e4f29ae6e418e8c4fe9456254311f6e642b8c9': {'title': [13],\n  'abstract': [32, 57]},\n '8cb34cbdcf65c23ef98430441b14a648c4e8d992': {'title': [8], 'abstract': [16]},\n 'cf0ae306a5b485fbf391b60d026f75e008115500': {'title': [],\n  'abstract': [14, 95]},\n 'e19b57563b52b29664ea6f47cb99191620ed1530': {'title': [], 'abstract': [184]},\n '4434daf16a5888b54fe52f48f751a564644b316a': {'title': [], 'abstract': [51]},\n '06a4f5125ca5347f79aafea53f9bb05d1daa0a7e': {'title': [], 'abstract': [4]},\n '447afc6231eb05eb43040d1eedcc4ce8fb83dbdb': {'title': [1], 'abstract': []},\n '282b7ab87c9b503c1850cfddb22cd8d206406b11': {'title': [],\n  'abstract': [19, 269]},\n '418d842e79c9df1844e38a1602e6bfc657e7cd51': {'title': [], 'abstract': [35]},\n 'e64f6ef3e16ed0ce08710fb9eb7198dc021ec8cf': {'title': [8],\n  'abstract': [74, 90]},\n '9cfe870e09f627e2814572aa4e1e7bff8b657fc5': {'title': [9], 'abstract': []},\n 'b360c69b87334c3ff37472a548a26db45fc8f3d4': {'title': [0],\n  'abstract': [0, 65]},\n '641febfe83546ba45e1131d95a5f84261f8a7156': {'title': [], 'abstract': [118]},\n 'f4966c81b9fe6476e8d418b75308b36f44865541': {'title': [], 'abstract': [88]},\n '3e2b056a68d174410c537437fecee45dcf6b71cb': {'title': [1], 'abstract': []},\n '6aff4621082f70b1bfa65feb62a07fd57a944637': {'title': [0], 'abstract': []},\n '898cbe37e30e81c92c501c4780bc5d8560f7560c': {'title': [], 'abstract': [12]},\n '59ee991e56a1894c2f50b2428ba92d4748e06a49': {'title': [0], 'abstract': []},\n '231af6ae64a0c6794f710f88dea1fdd4fd450776': {'title': [0], 'abstract': [168]},\n '334398a6d0f817de10ee8c64744c6bcf14debe22': {'title': [], 'abstract': [194]},\n '9f9cd21d2f896cc4d528ce81d01f1212807fb759': {'title': [5], 'abstract': [4]},\n 'a0a28ebafa06007bbef9473edd71b3a290a7010a': {'title': [],\n  'abstract': [32, 99]},\n 'f2296544c0e1ea7aabe3f996f4ac139f1ac3de65': {'title': [4],\n  'abstract': [70, 75, 84, 102, 109, 187, 218, 252, 274, 287, 329]},\n 'a3cbabdfb2e0ca39b77ad33b665ec2becc6937f6': {'title': [0],\n  'abstract': [22, 35, 273]},\n '7ea9f9a2fe19206c45ec5c78f9fc89c8bcea2a57': {'title': [2], 'abstract': [0]},\n 'f19284f6ab802c8a1fcde076fcb3fba195a71723': {'title': [6], 'abstract': [6]},\n 'a06ca7bb7f534460d386251f15100d21563332dc': {'title': [], 'abstract': [0]},\n '3f645e2615ad89edc544556e5a4e7dd887bd4413': {'title': [], 'abstract': [104]},\n '9cc8609f904c50b1be408abede7ab7f5cdbc9744': {'title': [5],\n  'abstract': [88, 207]},\n 'e8705ab4b9626c1ab6442483731fe0371f2234b6': {'title': [], 'abstract': [67]},\n '3ac513ac6b1d12f12805597c196a1866a46d465d': {'title': [], 'abstract': [12]},\n 'c037ed4522210aa37fda97292cb8e1a86a0f3338': {'title': [],\n  'abstract': [144, 225, 269]},\n 'b5640d037603e53ac304beb2bb577166b8c111bc': {'title': [], 'abstract': [14]},\n '0918125daacb6c2b3a2d3f155ad095d5ae8fb9b9': {'title': [], 'abstract': [99]},\n '2db20cde973f30dd6c3fbf207c4500546ae73758': {'title': [],\n  'abstract': [199, 204]},\n '85106fc0a68a575166f0f18456fa755b7a2660a3': {'title': [0], 'abstract': [69]},\n '0329d9be8ab1e3a1d5e4b9e7db5af5bbcc64e36f': {'title': [0], 'abstract': [38]},\n 'd56c9979027122544a5b5c7e2708304b900974f9': {'title': [3],\n  'abstract': [0, 48, 163]},\n '3cf5f512b30187efa088b9ee6c4e9d8fa7f937ce': {'title': [],\n  'abstract': [0, 54, 64, 81, 107, 163, 245]},\n '01a17c97a093d5c2ed3ed435e3acdbe5ecd9c8b7': {'title': [1], 'abstract': [0]},\n '235e215e2abf256f1b3c6b501f03a86ed6c354a9': {'title': [11],\n  'abstract': [90, 109, 130]},\n '81f0e648e4776dcbe933bda553f6ac4e5b31876e': {'title': [], 'abstract': [0]},\n '34310603e4a4bdb0a5d9c66d052608e4393d1e36': {'title': [], 'abstract': [212]},\n '632841ebaf485cd55e225ce8fb7e03fae6dedd3a': {'title': [],\n  'abstract': [0, 66, 200]},\n '17eb3834afebb8100a5b07467e73c38cd4baff48': {'title': [],\n  'abstract': [25, 53]},\n '864e033c002c5ec48d4c273c53ce995682fc3e21': {'title': [0], 'abstract': [3]},\n '907080efc9f5bae9cc7079670f993d60c90b1820': {'title': [14],\n  'abstract': [134, 139]},\n 'ab95d333d1f60b7546bbbdf8cb0ed816164430db': {'title': [], 'abstract': [8]},\n '4c67562906386ee9a876fae37fa82e0348db9e2c': {'title': [0],\n  'abstract': [50, 97, 120, 153]},\n '338c55f43bc6bce1174a766b9f6bd2fec4cf6c5e': {'title': [], 'abstract': [20]},\n '0c555ef3e1d5dee7fd9c7a4e25da678710c4304d': {'title': [3], 'abstract': [105]},\n 'e1026f240d59a80493de8f55521aa32f1d9b04d1': {'title': [11],\n  'abstract': [65, 177]},\n '37595f7a51982d776e57c7280b9445474d90f0be': {'title': [10],\n  'abstract': [85, 129]},\n 'c1aec79da632035a8a3a077b75323aed24d89ef8': {'title': [14], 'abstract': []},\n '980621fee9b902815c1de19ed726080b609594cf': {'title': [],\n  'abstract': [28, 142]},\n 'df70949731ba70b417a5de721e4d40775b2a56ba': {'title': [0], 'abstract': []},\n 'd7bb32e9475cc5d277cb58907404f7dbc24270a7': {'title': [9], 'abstract': []},\n '845e6824681a937328f628cb4028ae1bf3d63630': {'title': [0],\n  'abstract': [5, 64, 153]},\n 'f6e0856b4a9199fa968ac00da612a9407b5cb85c': {'title': [4], 'abstract': [128]},\n 'f4fea83e3c9a849fb6bd4ea039f6feacfb0c3d49': {'title': [], 'abstract': [15]},\n '6088a5af7198e763f9d6a9a5e78f45302228a3ff': {'title': [3],\n  'abstract': [1, 118]},\n '760ab37ab4d5a68b53035208d2e179494d879322': {'title': [],\n  'abstract': [60, 87]},\n '0ca95a34c0a59132e7f0925b189de884e51a93a6': {'title': [9],\n  'abstract': [51, 77, 204]},\n 'b99e54eb2d0556b8a74fd8d904bf6fd7db80a67b': {'title': [2], 'abstract': []},\n 'e0f73e991514450bb0f14f799878d84adc8601f9': {'title': [3], 'abstract': []},\n '743bbb51865843ff0bd5d598bb06b1bef3de5da4': {'title': [], 'abstract': [12]},\n 'e078ee00ad8e83a455e4b3f392179ea9b545099e': {'title': [0],\n  'abstract': [42, 82, 115, 149, 169, 189]},\n 'e1e256d899fadcdafc8aff873e6e8084f8133051': {'title': [5], 'abstract': []},\n 'c112084e0b3e18de82cd1e188b97c8a5997c3e65': {'title': [12],\n  'abstract': [3, 176]},\n '1c827db71b9399383684e1253222b90a9f9db734': {'title': [0], 'abstract': []},\n 'a39357450cab9b524048eda9f3593144cd0b3d5f': {'title': [], 'abstract': [84]},\n 'd12f8a7e5b38b32257e9c7173abc6ca0860b87c7': {'title': [0],\n  'abstract': [5, 30]},\n '1c7d41daf8d509dcd036060c877ee8013c13044b': {'title': [], 'abstract': [1]},\n '020bb2ba5f3923858cd6882ba5c5a44ea8041ab6': {'title': [], 'abstract': [73]},\n '6ccff03bb91388f0a46233dab167f79de7808224': {'title': [], 'abstract': [81]},\n '9b5b3e0d84380f39fde7eedd1a52bdccc959f031': {'title': [11], 'abstract': []},\n '5ff28f5044211577799d1383fbcc5f3e93ea56a3': {'title': [4],\n  'abstract': [0, 35, 52, 73, 84, 100, 128, 143, 154]},\n '40443efff872c38346993f222d54dda0d44cbb47': {'title': [13], 'abstract': []},\n 'ab0d859e726527cb18fb63fd4c1f18cba39c92d5': {'title': [], 'abstract': [61]},\n '84599e152d96b9c33cd216339e8d2a600111a660': {'title': [], 'abstract': [164]},\n '512ba6e96840ff5f33525534c515546dd007370e': {'title': [], 'abstract': [6]},\n '137ffab2db25084e8fb31e4f537711356791b509': {'title': [11],\n  'abstract': [6, 30]},\n '1e80f755bcbf10479afd2338cec05211fdbd325c': {'title': [1],\n  'abstract': [14, 44]},\n 'aa29749fb3034ba3fab8874e132a034a9b0f6e55': {'title': [0], 'abstract': []},\n '1770450f74ac68af89b7dee0c2ab1ce12f43ed02': {'title': [7], 'abstract': []},\n '6ce6768a34e197e4ef76933c8e6760b6e4833dc4': {'title': [4], 'abstract': [18]},\n '05fd1da7b2e34f86ec7f010bef068717ae964332': {'title': [4],\n  'abstract': [0, 40, 93, 226]},\n '0299fb306366c8f72dc4c8e38cb111755b5a4f70': {'title': [],\n  'abstract': [96, 104]},\n '147f1408e235bf5d1410474505ed773494e3ab01': {'title': [1],\n  'abstract': [11, 48, 85, 102, 159]},\n 'd2b62f77cb2864e465aa60bca6c26bb1d2f84963': {'title': [3], 'abstract': [40]},\n 'e15cf50aa89fee8535703b9f9512fca5bfc43327': {'title': [1],\n  'abstract': [3, 114]},\n '54c6416eae67bce7b3f058601e0c758e39f33a62': {'title': [5], 'abstract': [41]},\n '7cfa5c97164129ce3630511f639040d28db1d4b7': {'title': [], 'abstract': [78]},\n 'cab372bc3824780cce20d9dd1c22d4df39ed081a': {'title': [0, 6],\n  'abstract': [12, 70, 236]},\n '7c1e5810f889a1cfbcb2e0a0883761a6d5e76f9a': {'title': [], 'abstract': [191]},\n '47966b673a145dfba9880c207ab4e21d692ab563': {'title': [],\n  'abstract': [6, 102, 174]},\n '24d5152ba816d974789a159c804141befcc2f3d5': {'title': [4], 'abstract': []},\n '74261ae216e457a2d2635d06f0425db4a4ce1b1f': {'title': [7], 'abstract': []},\n 'd04cf73d35b94f8404d4086b41a85fbe70c8cf0f': {'title': [0], 'abstract': []},\n '41eaa127a82fe94fc31d06c6f8dfeaa5e0d4cb9d': {'title': [13], 'abstract': [46]},\n 'ed2a99a4982328462e34c944efbb33a65e6d823c': {'title': [], 'abstract': [53]},\n '250ac5f01aa125bd2a3188d183c68eca185f2054': {'title': [0], 'abstract': []},\n 'dd3c8428b0b8f41e48ad9632c4acf63e9bbd2a4a': {'title': [],\n  'abstract': [62, 90, 132]},\n 'b8375ff50b8a6f1a10dd809129a18df96888ac8b': {'title': [], 'abstract': [3]},\n 'bf599a6863c524dda9a1b6dbc5ecbb2e31e556a4': {'title': [10],\n  'abstract': [139]},\n '791b65c65f8ae7e16c1ee9203cdc3ee59ffeb99f': {'title': [4], 'abstract': [83]},\n 'da2af21706fabe977bdd12d8b449d8d3a04fb7fb': {'title': [],\n  'abstract': [0, 71]},\n 'b143bde4c6db2e6cc7eac580fbf1a2ff756dbe10': {'title': [], 'abstract': [133]},\n 'a1585ce06007b95185a47929fa9e8bd0048af747': {'title': [6],\n  'abstract': [7, 12, 65, 91, 106]},\n '8414bcdd8de21e8f76c0191dc9e41808772b16d7': {'title': [0], 'abstract': []},\n 'be2e44f4f455db958e41a5dcd80dfe302597dd66': {'title': [14],\n  'abstract': [16, 36, 205, 229, 275]},\n '94a96f64bd93ad91642fa04da09bb709a26ac277': {'title': [], 'abstract': [18]},\n 'd6fff78f45db5e8a6246d256d58a047c7647059f': {'title': [1], 'abstract': [8]},\n 'd65eb30e5f0d2013fd5e4f45d1413bc2969ee803': {'title': [9], 'abstract': [0]},\n '454a7f56b6b3cb870913d19ad9a6f862aa7ea8b0': {'title': [], 'abstract': [25]},\n '3944c123f87d3609370711168edb6348e5e359ae': {'title': [7], 'abstract': []},\n 'df0402517a7338ae28bc54acaac400de6b456a46': {'title': [], 'abstract': [6]},\n 'aab0ae5560545489faa54d7942cdae851d30fdf4': {'title': [3],\n  'abstract': [22, 181]},\n '20c53d638c4a408de715772be2506a5a30b89084': {'title': [], 'abstract': [99]},\n 'df18e1bebedd8fe9c4a090024f85867d9f39b185': {'title': [10],\n  'abstract': [5, 31, 113]},\n '70cc24881732c04bd74437660bda970ac299562a': {'title': [], 'abstract': [107]},\n 'aca9fdb07b2f4970528bcb63b4bc6e6cdf948a99': {'title': [], 'abstract': [104]},\n '0389b91df44cab0bc0f11dadcb29b296653dde0c': {'title': [0],\n  'abstract': [159, 178]},\n '17e9a972dbce908dc1d4e35a6ae9e8737f6eab44': {'title': [2], 'abstract': []},\n '00acfa59f37ded6531917b4746d5a19306547ba8': {'title': [], 'abstract': [4]},\n '93780d6c0e0d537bca3f24245618033ecb7ff4e3': {'title': [], 'abstract': [16]},\n 'd0ecbd7eafe0eefd3a5ee6cc4eb32ec2a29f5161': {'title': [10], 'abstract': [88]},\n 'aaeb0b43287d80568e5b8db4da2fce8d1ba033bf': {'title': [9], 'abstract': [108]},\n '4fdefd6ca91e7fa80873e51f029f596b07eda70c': {'title': [],\n  'abstract': [75, 139]},\n 'a0c36c58d3211635ff50ac161ff43d249ea2f115': {'title': [6], 'abstract': []},\n '834d1723455e3f70040c407d80c5dd6ba7794021': {'title': [], 'abstract': [40]},\n 'f370bfea290f84005873849c080852bf0e132af8': {'title': [], 'abstract': [6]},\n '5b48a06ac2d2d778c09acbcae70ba6fab7f65fe8': {'title': [], 'abstract': [117]},\n '0b87a873e89319ffff55d967f4c26e2e7b4dd595': {'title': [], 'abstract': [54]},\n 'ed24940637b0b6f520f9cc18c8fb92b85ce2cebb': {'title': [7], 'abstract': []},\n '7d21a1ba26119b264e04392a2314de8375b48ee9': {'title': [5], 'abstract': []},\n '8deaa7ded506c00b5e0ee37df7ba3a73817b79cb': {'title': [3], 'abstract': []},\n '4af81b39570063c4e2b9832171ef61369e4d8b30': {'title': [], 'abstract': [84]},\n '081651b38ff7533550a3adfc1c00da333a8fe86c': {'title': [5],\n  'abstract': [1, 102]},\n '9064e84262241d50b1c6963c306cb8ebdc594a1b': {'title': [6], 'abstract': []},\n '75117523048883a98dbd4924d7a1953d7bd79ec9': {'title': [],\n  'abstract': [109, 247, 333]},\n '1c5d30301720db9981b79df6b0968f6615d290a1': {'title': [],\n  'abstract': [58, 81]},\n '58cee926e5d7b594d9973638c76b7c1639562c17': {'title': [3], 'abstract': [8]},\n '329a7e9bcde85bfe11e90895aca2e905fd9228f5': {'title': [0], 'abstract': []},\n 'f0f94dfc1b95ec94c7a371ae1281727eafe604da': {'title': [], 'abstract': [83]}}"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1 points\n",
    "\n",
    "def get_posting_list(trie: TrieNode, word: str, get_char_index: bool = False) -> Dict[\n",
    "    str, Dict[Literal['title', 'abstract'], List[int]]]:\n",
    "    \"\"\" get posting_list of a word\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        trie: TrieNode\n",
    "            trie of corpus\n",
    "        word: str\n",
    "             word we want to check\n",
    "        get_char_index: bool\n",
    "            if True, return char index of word in doc (default is False)\n",
    "\n",
    "        Return\n",
    "        ----------\n",
    "        dict \n",
    "            posting list\n",
    "\n",
    "    \"\"\"\n",
    "    tokens = clean_data(word)\n",
    "    assert len(tokens) == 1, 'word must be a single token'\n",
    "    token = tokens[0]\n",
    "    return trie.search(token, get_char_index=get_char_index)\n",
    "\n",
    "\n",
    "get_posting_list(ai_bio_trie, 'Deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>پویا‌سازی نمایه (۷ + ۷ نمره)</b>\n",
    "    </h1>\n",
    "</font>\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    برای پویا سازی نمایه ایجاد شده باید قابلیت حذف و اضافه تک داکیومنت اضافه شود .<br>\n",
    "    برای اضافه شدن داکیومنت، به تابع ()add_documnet یک سه‌تایی داده می‌شود که اطلاعات مربوط به داکیومنت شامل شناسه، عنوان و چکیده در آن به ترتیب قرار دارد. در صورت نبود آن سند در نمایه‌ها، به نمایه‌ها اضافه می‌شود.<br>\n",
    "     برای حذف داکیومنت نیز شناسه آن به تابع ()remove_document داده می‌شود.<br>\n",
    "    تضمین می‌شود که شرط یکتا بودن شناسه داکیومنت‌ها نقض نشود. برای مثال دو داکیومنت با شناسه یکسان به مجموعه اضافه نخواهد شد. البته ممکن است حذف شده و دوباره اضافه شود.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7 points\n",
    "\n",
    "def add_document(trie: TrieNode, document: tuple):\n",
    "    \"\"\"Adds a document to positional index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trie: TrieNode\n",
    "        trie of corpus\n",
    "    document : str\n",
    "        Comma separated string containing id,title,abstract in this exact order\n",
    "    \"\"\"\n",
    "\n",
    "    doc_id, title, abstract = document\n",
    "    for doc_section, text in [('title', title), ('abstract', abstract)]:\n",
    "        for token in clean_data(text):\n",
    "            trie.insert(doc_id, doc_section, token)\n",
    "\n",
    "\n",
    "new_document = (\"1eae26fe1ca566f17468080c3aecab1c3f9efb66\",\n",
    "                \"A Deep Learning Framework for Viable Tumor Burden Estimation\",\n",
    "                \"Liver masses have become a common clinical challenge since they require to be defined and accurately categorized as neoplastic or nonneoplastic lesions. Hepatocellular carcinoma (HCC), the most common histologic type of primary liver malignancy, is a global health concern being the fifth most common cancer and the second cause of cancer mortality worldwide. Accurate diagnosis, which in some circumstances requires histopathology results, is necessary for appropriate management. Also, some tumor characteristics help in predicting tumor behavior and patient response to therapy. In this paper, we propose a deep learning framework for the segmentation of whole and viable tumor areas of liver cancer from whole-slide images (WSIs). To this end, we use Fast Segmentation Convolutional Neural Network (Fast-SCNN) as our network. We use the dataset from PAIP 2019 challenge. After data-augmentation on the training subset, we train the network with a multi-term loss function and SWA technique. Our model achieves 0.80 for the median of the Jaccard Index for the task of Viable Tumor Segmentation and 0.77 for the median of Weighted Absolute Accuracy for the task of Viable Tumor Burden Estimation on the whole-slide images of the test subset.\")\n",
    "add_document(ai_bio_trie, new_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7 points\n",
    "\n",
    "def remove_document(document_id: str):\n",
    "    \"\"\"removes a document from positional index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document_id : str\n",
    "        Id of the document\n",
    "    \"\"\"\n",
    "    ai_bio_trie.remove_document(document_id)\n",
    "\n",
    "\n",
    "remove_document(\"1eae26fe1ca566f17468080c3aecab1c3f9efb66\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>ذخیره و فشرده‌سازی نمایه (۱۳ + ۷\n",
    "     نمره)</b>\n",
    "    </h1>\n",
    "</font>\n",
    "<font face=\"XB Zar\" size=3>\n",
    "    در این بخش باید توانایی ذخیره کردن نمایه و بارگذاری مجدد آن را به سامانه اضافه کنید.<br>\n",
    "    ذخیره‌سازی به ۳ روش صورت می‌گیرد.<br>\n",
    "     <ul>\n",
    "    <li>no-compression</li>\n",
    "    <li>gamma-code</li>\n",
    "    <li>variable-byte</li>\n",
    "    </ul> \n",
    "      روش‌های فشرده‌سازی باید توسط خودتان پیاده‌سازی شود.\n",
    "    برای ذخیره نمایه در فایل نیز از JSON  یا TXT استفاده کنید. \n",
    "    نام فایل خود را نوع فشرده‌سازی بگذارید و در یک فایل زیپ قرار دهید و آیلود کنید.\n",
    "    <br>\n",
    "     بخشی از نمره شما در این قسمت به میزان فشرده‌سازی نمایه اختصاص داده شده است. بنابراین پیاده‌سازی بهینه روش‌های فشرده‌سازی مهم است.<br>\n",
    "     تابع load_index برای بارگذاری نمایه است با گرفتن مسیر فایل ذخیره شده نمایه با نام path نمایه را از این فایل بارگذاری می‌کند.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "358854702"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 13 points\n",
    "\n",
    "def store_index(trie: TrieNode, path: str, compression_type: str) -> int:\n",
    "    \"\"\"Stores the index in a file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trie: TrieNode\n",
    "        trie of corpus\n",
    "    path : str\n",
    "        Path to store the file\n",
    "    compression_type : str\n",
    "        Could be one of the followings:\n",
    "        - no-compression\n",
    "        - gamma-code\n",
    "        - variable-byte\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "    int\n",
    "        The size of the stored file\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    if compression_type == \"no-compression\":\n",
    "        import json\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(trie.to_dict(), f)\n",
    "        file_size = os.stat(path).st_size\n",
    "    else:\n",
    "        raise ValueError(\"compression_type should be one of the followings: no-compression, gamma-code, variable-byte\")\n",
    "    return file_size\n",
    "\n",
    "\n",
    "store_index(ai_bio_trie, \"index/ai-bio/no-compression.json\", \"no-compression\")\n",
    "# store_index(hw_sys_trie, \"index/hw-sys/no-compression.json\", \"no-compression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7 points\n",
    "\n",
    "def load_index(path: str, compression_type: str) -> TrieNode:\n",
    "    \"\"\"Loads the index from a file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path of the file to load from\n",
    "\n",
    "    compression_type : str\n",
    "        Could be one of the followings:\n",
    "        - no-compression\n",
    "        - gamma-code\n",
    "        - variable-byte\n",
    "    \"\"\"\n",
    "    if compression_type == 'no-compression':\n",
    "        import json\n",
    "        with open(path, 'r') as f:\n",
    "            trie_dict = json.load(f)\n",
    "        return TrieNode.from_dict(trie_dict)\n",
    "    else:\n",
    "        raise ValueError(\"compression_type should be one of the followings: no-compression, gamma-code, variable-byte\")\n",
    "\n",
    "\n",
    "ai_bio_trie = load_index(\"index/ai-bio/no-compression.json\", \"no-compression\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>اصلاح پرسمان (۳ + ۹\n",
    "     نمره)</b>\n",
    "    </h1>\n",
    "    در صورتی که پرسمان ورودی دارای غلط املایی باشد یا به عبارتی لغاتی از آن در لغت‌نامه موجود نباشد، لازم است که با جستجوی لغات احتمالی و اصلاح پرسمان به ادامه جستجو پرداخته شود.\n",
    "    <br>\n",
    "    <br>\n",
    "    برای اینکار ابتدا باید bigramهای لغت را به دست آورید، سپس با معیار jaccard بیست لغتی که بیشترین تعداد bigram مشترک با لغت مورد نظر را دارند بدست آورید. در آخر با معیار minimum edit distance لغت جایگزین را برای لغت مورد نظر پیدا کنید.\n",
    "    <br>\n",
    "    <br>\n",
    "    نیازی به ذخیره‌سازی و فشرده‌سازی نمایه bigram نیست. همچنین می‌توانید از کد آماده برای محاسبه edit distance استفاده کنید.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 points\n",
    "\n",
    "WORD_BOUNDARY_CHAR = '¶'\n",
    "\n",
    "\n",
    "def get_word_bigrams(word: str) -> Iterable[str]:\n",
    "    \"\"\"\n",
    "    Returns the bigrams of the given word\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    word: str\n",
    "        The word to get the bigrams from\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of bigrams\n",
    "    \"\"\"\n",
    "    word = WORD_BOUNDARY_CHAR + word + WORD_BOUNDARY_CHAR\n",
    "    return [word[i:i + 2] for i in range(len(word) - 1)]\n",
    "\n",
    "\n",
    "def create_bigram_index(corpus: Corpus) -> Dict[str, Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Creates a bigram index for the spell correction\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus: Corpus\n",
    "        The corpus to generate the bigram index from\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary of bigrams and their occurence\n",
    "    \"\"\"\n",
    "    bigram_index: Dict[str, Dict[str, int]] = {}\n",
    "    seen_words = set()\n",
    "    for doc_id, doc in corpus.cleaned_documents.items():\n",
    "        for doc_section in doc.values():\n",
    "            for token in doc_section:\n",
    "                if token.actual in seen_words:\n",
    "                    continue\n",
    "                seen_words.add(token.actual)\n",
    "                for bigram in get_word_bigrams(token.actual):\n",
    "                    if bigram not in bigram_index:\n",
    "                        bigram_index[bigram] = {}\n",
    "                    if token.actual not in bigram_index[bigram]:\n",
    "                        bigram_index[bigram][token.actual] = 0\n",
    "                    bigram_index[bigram][token.actual] += 1\n",
    "    return bigram_index\n",
    "\n",
    "\n",
    "ai_bio_bigram_index = create_bigram_index(ai_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'this is a deep learning-based network trained with imagenet dataset on classification task'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 9 points\n",
    "\n",
    "def correct_text(bigram_index: Dict[str, Dict[str, int]], text: str, similar_words_limit: int = 20) -> str:\n",
    "    \"\"\"\n",
    "    Correct the give query text, if it is misspelled\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    bigram_index: Dict[str, Dict[str, int]]\n",
    "        The bigram index to search in\n",
    "    text: str\n",
    "        The query text\n",
    "    similar_words_limit: int\n",
    "        The number of similar words\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    str\n",
    "        The corrected form of the given text\n",
    "    \"\"\"\n",
    "    corrected_text = ''.join(text)\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    for token in nlp(text):\n",
    "        word = token.text\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        word_occurences: Dict[str, int] = {}\n",
    "        for bigram in get_word_bigrams(word):\n",
    "            for posting, occurence in bigram_index.get(bigram, {}).items():\n",
    "                if posting not in word_occurences:\n",
    "                    word_occurences[posting] = 0\n",
    "                word_occurences[posting] += occurence\n",
    "        for posting, word_occurence in word_occurences.items():\n",
    "            if (len(word) + len(posting) + 2 - word_occurence) == 0:\n",
    "                print(word, posting, word_occurence)\n",
    "        jaccard_scores = {\n",
    "            posting: word_occurence / (len(word) + len(posting) + 2 - word_occurence)\n",
    "            for posting, word_occurence in word_occurences.items()\n",
    "        }\n",
    "        similar_words = sorted(jaccard_scores, key=jaccard_scores.get, reverse=True)[:similar_words_limit]\n",
    "        min_edit_distance = float('inf')\n",
    "        corrected_word = word\n",
    "        for similar_word in similar_words:\n",
    "            if (edit_distance := nltkd.edit_distance(similar_word, word)) < min_edit_distance:\n",
    "                min_edit_distance = edit_distance\n",
    "                corrected_word = similar_word\n",
    "        corrected_text = corrected_text.replace(word, corrected_word)\n",
    "    return corrected_text\n",
    "\n",
    "\n",
    "correct_text(ai_bio_bigram_index,\n",
    "             \"ths is a deap learnig-based netwark trained wit imagenat dasadet on clasification tsk\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>جستجو و بازیابی اسناد (۲۰ + ۵ نمره)</b>\n",
    "    </h1>\n",
    "در این بخش لازم است که شما پرسمانی را که از کاربر میگیرید، در مجموعه اسناد نمایه شده جست و جو کنید. توجه داشته باشید که جست و جویی که انجام میدهید هم باید در عنوان مقاله و هم در چکیده آن انجام شود. در نهایت، اسناد باید به ترتیب امتیاز نهاییشان برگردانده شوند. امتیاز نهایی هر سند نیز از جمع وزن دار امتیاز جست و جو در عنوان و جست و جو در چکیده مقاله به دست می آید.\n",
    "<br>\n",
    "حال به توضیح چگونگی جست و جو میپردازیم. حال به توضیح چگونگی جست و جو میپردازیم. در این قسمت بنا بر این است که دو روش جستجو را پیاده سازی کنید. روش اول جست و جو، جست و جو ترتیب دار در فضای برداری \n",
    "<b>tf-idf</b>\n",
    "به روش های <b>ltn-lnn</b> و <b>ltc-lnc</b> می باشد. \n",
    "روش دوم، جستجو بر اساس احتمال (روش Okapi BM25) است.\n",
    "<br>\n",
    "به طور کلی، شما به کمک وزنی که به عنوان ورودی به تابع خود میدهید، میتوانید امتیاز نهایی را مطابق زیر محاسبه کنید. توجه داشته باشید که این وزن عددی بین 0 و 1 است و بدیهی است که در صورت مثلا صفر بودن (در مثال زیر) تاثیر عنوان در جست و جوی شما حذف می شود\n",
    "<br>\n",
    "\n",
    "\n",
    "final score = weight * abstract_score + (1 - weight) * title_score\n",
    "\n",
    "\n",
    "در روش دوم، نیاز است تا روش بازیابی اطلاعات بر اساس احتمالات را پیاده سازی کنید که در اسلایدهای مربوط به این قسمت توضیح داده شده است.\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "در تابع search که مربوط به جست و جوی پرسمان کلی است، به عنوان ورودی پارامتر پرسمان (query)، روش محاسبه امتیاز(method)، تعداد اسنادی که باید برگردانده شود (n) را ورودی می گیرید. علاوه بر این، به کمک پارامتر ورودی mode مشخص خواهید کرد که آیا جست و جو در عنوان مقاله و چکیده آن به طور جدا انجام می شود یا خیر و به کمک ورودی where نیز مشخص می کنیم که اگر قرار بود جست و جوی پرسمان. تنها در یکی از آنها انجام شود، کدام است.\n",
    "\n",
    "پس از به دست آوردن لیست خروجی‌ها، در صورتی که ورودی\n",
    "print\n",
    "مقدار\n",
    "True\n",
    "داشت، لیست مقالات را به صورت خوانا و همراه با \n",
    "snippet\n",
    "در خروجی چاپ کنید (۵ نمره).\n",
    "</div>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 25 points\n",
    "\n",
    "\n",
    "def ltn_lnn(corpus: Corpus, doc_section: Literal['title', 'abstract'],\n",
    "            token_search_results: Dict[str, Dict[str, Dict[Literal['title', 'abstract'], List[int]]]]) -> Dict[\n",
    "    str, float]:\n",
    "    tf = {\n",
    "        token: {\n",
    "            doc_id: len(doc[doc_section])\n",
    "            for doc_id, doc in search_results.items()\n",
    "        }\n",
    "        for token, search_results in token_search_results.items()\n",
    "    }\n",
    "    w_tf = {\n",
    "        token: {\n",
    "            doc_id: 1 + math.log(tf) if tf > 0 else 0\n",
    "            for doc_id, tf in tf.items()\n",
    "        }\n",
    "        for token, tf in tf.items()\n",
    "    }\n",
    "    df = {\n",
    "        token: len(search_results)\n",
    "        for token, search_results in token_search_results.items()\n",
    "    }\n",
    "    w_idf = {\n",
    "        token: math.log(len(corpus) / df)\n",
    "        for token, df in df.items()\n",
    "    }\n",
    "    doc_scores = {}\n",
    "    for token, token_w_tf in w_tf.items():\n",
    "        for doc_id, w in token_w_tf.items():\n",
    "            doc_scores[doc_id] = doc_scores.get(doc_id, 0.0) + w * w_idf[token]\n",
    "    return doc_scores\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    doc_id: str\n",
    "    score: float\n",
    "    title: str\n",
    "    abstract: str\n",
    "\n",
    "\n",
    "def highlight_text(text: str, highlight_starts: List[int]) -> str:\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    result = ''\n",
    "    last_index = 0\n",
    "    highlight_starts = sorted(highlight_starts)\n",
    "    for i, highlight_start in enumerate(highlight_starts):\n",
    "        next_start = highlight_starts[i + 1] if i + 1 < len(highlight_starts) else len(text)\n",
    "        token = nlp(text[highlight_start:next_start])[0]\n",
    "        highlight_length = len(token)\n",
    "        result += text[last_index:highlight_start] + \\\n",
    "                  colored(text[highlight_start:highlight_start + highlight_length], 'red')\n",
    "        last_index = highlight_start + highlight_length\n",
    "    result += text[last_index:]\n",
    "    return result\n",
    "\n",
    "\n",
    "def search(corpus: Corpus, trie: TrieNode, bigram_index: Dict[str, Dict[str, int]], query: str, max_result_count: int,\n",
    "           method: str = 'ltn-lnn', weight: float = 0.5, highlight: bool = False, print_result: bool = False):\n",
    "    \"\"\"\n",
    "        Finds relevant documents to query\n",
    "        \n",
    "        Parameters\n",
    "        ---------------------------------------------------------------------------------------------------\n",
    "        corpus: Corpus\n",
    "            The corpus\n",
    "        trie: TrieNode\n",
    "            The trie\n",
    "        bigram_index: Dict[str, Dict[str, int]]\n",
    "            The bigram index\n",
    "        query: str\n",
    "            The query string\n",
    "        max_result_count: int\n",
    "            Return top 'max_result_count' docs which have the highest scores.\n",
    "            notice that if max_result_count = -1, then you have to return all docs\n",
    "        method: 'ltn-lnn' or 'ltc-lnc' or 'okapi25'\n",
    "        weight: float\n",
    "            weight of abstract score\n",
    "        highlight: bool\n",
    "            If True, highlight the query tokens in search results\n",
    "        print_result: bool\n",
    "            If True, print the results in a readable format\n",
    "\n",
    "        Returns\n",
    "        ----------------------------------------------------------------------------------------------------\n",
    "        list\n",
    "            Retrieved documents with snippet\n",
    "    \"\"\"\n",
    "    corrected_query = correct_text(bigram_index, query)\n",
    "    if print_result:\n",
    "        print(f'Query'.center(100, '-'))\n",
    "        print(corrected_query.center(100, '-'))\n",
    "        print('-' * 100)\n",
    "    query_tokens = [token.processed\n",
    "                    for token in clean_data(corrected_query)\n",
    "                    if token.processed not in corpus.stop_tokens]\n",
    "    token_search_results: Dict[str, Dict[str, Dict[Literal['title', 'abstract'], List[int]]]] = {\n",
    "        token: trie.search(token, get_char_index=True) or {}\n",
    "        for token in query_tokens\n",
    "    }\n",
    "    if method == 'ltn-lnn':\n",
    "        title_doc_scores = ltn_lnn(corpus, 'title', token_search_results)\n",
    "        abstract_doc_scores = ltn_lnn(corpus, 'abstract', token_search_results)\n",
    "    else:\n",
    "        raise ValueError(f'Expected the method to be one of \\'ltn-lnn\\', \\'ltc-lnc\\', or \\'okapi25\\', bot got {method}')\n",
    "    doc_scores = {\n",
    "        doc_id: weight * abstract_doc_scores.get(doc_id, 0.0) + (1 - weight) * title_doc_scores.get(doc_id, 0.0)\n",
    "        for doc_id in set(title_doc_scores.keys()) | set(abstract_doc_scores.keys())\n",
    "    }\n",
    "    if highlight:\n",
    "        doc_highlights = {\n",
    "            doc_id: {\n",
    "                'title': sum([\n",
    "                    token_search_results[token][doc_id]['title']\n",
    "                    for token in query_tokens\n",
    "                    if token in token_search_results and doc_id in token_search_results[token]\n",
    "                ], []),\n",
    "                'abstract': sum([\n",
    "                    token_search_results[token][doc_id]['abstract']\n",
    "                    for token in query_tokens\n",
    "                    if token in token_search_results and doc_id in token_search_results[token]\n",
    "                ], [])\n",
    "            }\n",
    "            for doc_id in doc_scores\n",
    "        }\n",
    "    else:\n",
    "        doc_highlights = {\n",
    "            doc_id: {\n",
    "                'title': [],\n",
    "                'abstract': [],\n",
    "            }\n",
    "            for doc_id in doc_scores\n",
    "        }\n",
    "    documents = [\n",
    "                    SearchResult(\n",
    "                        doc_id=doc_id,\n",
    "                        score=score,\n",
    "                        title=highlight_text(corpus.data[corpus.data['paperId'] == doc_id]['title'].item(), doc_highlights[doc_id]['title']),\n",
    "                        abstract=highlight_text(corpus.data[corpus.data['paperId'] == doc_id]['abstract'].item(), doc_highlights[doc_id]['abstract'])\n",
    "                    )\n",
    "                    for i, (doc_id, score) in enumerate(sorted(doc_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "                    if i < max_result_count or max_result_count == -1\n",
    "                ]\n",
    "    if print_result:\n",
    "        for i, doc in enumerate(documents):\n",
    "            print(f'# {i} - Document ID: {colored(doc.doc_id, \"green\")} - Score: {colored(doc.score, \"green\")}')\n",
    "            print(doc.title.center(100, '-'))\n",
    "            print(f'Abstract'.center(100, '-'))\n",
    "            print(doc.abstract)\n",
    "            print('-' * 100)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------Query------------------------------------------------\n",
      "-------------------------Super-resolution microscopy and fluorescent probes-------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 0 - Document ID: \u001B[32m2972aba5dbafaa4a0a2f9c1e7a014266d2ee2662\u001B[0m - Score: \u001B[32m42.59453494962725\u001B[0m\n",
      "Small-Molecule \u001B[31mFluorescent\u001B[0m \u001B[31mProbes\u001B[0m for Live-Cell \u001B[31mSuper-\u001B[0m\u001B[31mResolution\u001B[0m \u001B[31mMicroscopy\u001B[0m.\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "\u001B[31mSuper-\u001B[0m\u001B[31mresolution\u001B[0m fluorescence \u001B[31mmicroscopy\u001B[0m is a powerful tool to visualize biomolecules and cellular structures at the nanometer scale. Employing these techniques in living cells has opened up the possibility to study dynamic processes with unprecedented spatial and temporal \u001B[31mresolution\u001B[0m. Different physical approaches to \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m \u001B[31mmicroscopy\u001B[0m have been introduced over the last years. A bottleneck to apply these approaches for live-cell imaging has become the availability of appropriate \u001B[31mfluorescent\u001B[0m \u001B[31mprobes\u001B[0m that can be specifically attached to biomolecules. In this Perspective, we discuss the role of small-molecule \u001B[31mfluorescent\u001B[0m \u001B[31mprobes\u001B[0m for live-cell \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m \u001B[31mmicroscopy\u001B[0m and the challenges that need to be overcome for their generation. Recent trends in the development of labeling strategies are reviewed together with the required chemical and spectroscopic properties of the \u001B[31mprobes\u001B[0m. Finally, selected examples of the use of small-molecule \u001B[31mfluorescent\u001B[0m \u001B[31mprobes\u001B[0m in live-cell \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m \u001B[31mmicroscopy\u001B[0m are given. \n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 1 - Document ID: \u001B[32m5287251c71fddee0c8e9ba48a98b6a2212bfed66\u001B[0m - Score: \u001B[32m31.14919291168606\u001B[0m\n",
      "Recent Advances in \u001B[31mFluorescent\u001B[0m \u001B[31mProbes\u001B[0m for \u001B[31mSuper-\u001B[0m\u001B[31mResolution\u001B[0m \u001B[31mMicroscopy\u001B[0m\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "\u001B[31mSuper-\u001B[0m\u001B[31mresolution\u001B[0m \u001B[31mmicroscopy\u001B[0m (SRM) has become an indispensable tool for monitoring cytoskeleton dynamics, as well as the imaging, detection, and tracing of functional biomolecules in living cells. It overcomes the barrier of the diffraction limit and allows for the visualization of cellular structure down to the subnanometer level. Several types of SRM techniques are available, with a vast number of applications in interdisciplinary research fields. To date, many \u001B[31mfluorescent\u001B[0m \u001B[31mprobes\u001B[0m such as \u001B[31mfluorescent\u001B[0m proteins, organic dyes, nanomaterials, quantum dots, and carbon dots have been employed for \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m \u001B[31mmicroscopy\u001B[0m. Each one has its own limitations, and as such, improving the efficiency of these \u001B[31mprobes\u001B[0m to obtain a better-resolved structure is of great importance.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 2 - Document ID: \u001B[32m19ad54916caa9a8d79f57552d26dba5fb8debab0\u001B[0m - Score: \u001B[32m30.115066312032912\u001B[0m\n",
      "Author Correction: \u001B[31mSuper-\u001B[0m\u001B[31mresolution\u001B[0m \u001B[31mmicroscopy\u001B[0m compatible \u001B[31mfluorescent\u001B[0m \u001B[31mprobes\u001B[0m reveal endogenous glucagon-like peptide-1 receptor distribution and dynamics\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "The glucagon-like peptide-1 receptor (GLP1R) is a class B G protein-coupled receptor (GPCR) involved in metabolism. Presently, its visualization is limited to genetic manipulation, antibody detection or the use of \u001B[31mprobes\u001B[0m that stimulate receptor activation. Herein, we present LUXendin645, a far-red \u001B[31mfluorescent\u001B[0m GLP1R antagonistic peptide label. LUXendin645 produces intense and specific membrane labeling throughout live and fixed tissue. GLP1R signaling can additionally be evoked when the receptor is allosterically modulated in the presence of LUXendin645. Using LUXendin645 and LUXendin651, we describe islet, brain and hESC-derived β-like cell GLP1R expression patterns, reveal higher-order GLP1R organization including membrane nanodomains, and track single receptor subpopulations. We furthermore show that the LUXendin backbone can be optimized for intravital two-photon imaging by installing a red fluorophore. Thus, our \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m compatible labeling \u001B[31mprobes\u001B[0m allow visualization of endogenous GLP1R, and provide insight into class B GPCR distribution and dynamics both in vitro and in vivo. Glucagon-like peptide-1 receptor is an important regulator of appetite and glucose homeostasis. Here the authors describe \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m \u001B[31mmicroscopy\u001B[0m and in vivo imaging compatible \u001B[31mfluorescent\u001B[0m \u001B[31mprobes\u001B[0m, which reveal endogenous glucagon-like peptide-1 receptor distribution and dynamics in islets and brain. \n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 3 - Document ID: \u001B[32m1166830c929dcebae2b7002cb25b70145ccf88a3\u001B[0m - Score: \u001B[32m27.832143590799944\u001B[0m\n",
      "\u001B[31mFluorescent\u001B[0m \u001B[31mProbes\u001B[0m for \u001B[31mSuper-\u001B[0m\u001B[31mResolution\u001B[0m \u001B[31mMicroscopy\u001B[0m of Lysosomes\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "Lysosomes are membrane-enclosed small spherical cytoplasmic organelles. Malfunctioning and abnormalities in lysosomes can cause a plethora of neurodegenerative diseases. Consequently, understanding the structural information on lysosomes down to a subnanometer level is essential. Recently, \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m imaging techniques enable us to visualize dynamical processes occurring in suborganelle structures inside living cells down to subnanometer accuracy by breaking the diffraction limit. A brighter and highly photostable \u001B[31mfluorescent\u001B[0m \u001B[31mprobe\u001B[0m is essential for \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m \u001B[31mmicroscopy\u001B[0m. In this regard, this mini-review deals with the various types of \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m techniques and the \u001B[31mprobes\u001B[0m that are used to specifically stain and resolve the structure of the lysosomes. \n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 4 - Document ID: \u001B[32medf0b7ea5e74ea1c61cd48acbbef7013817bc6a2\u001B[0m - Score: \u001B[32m26.81881122495893\u001B[0m\n",
      "Antibody Functionalization of Ultrasmall \u001B[31mFluorescent\u001B[0m Core–Shell Aluminosilicate Nanoparticle \u001B[31mProbes\u001B[0m for Advanced Intracellular Labeling and Optical \u001B[31mSuper\u001B[0m \u001B[31mResolution\u001B[0m \u001B[31mMicroscopy\u001B[0m\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "\u001B[31mFluorescent\u001B[0m labeling of cellular substructures is commonly performed using antibody–organic dye conjugates. Organic dyes do not exhibit ideal optical properties in terms of brightness and photostability, however, in particular when it comes to advanced optical \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m \u001B[31mmicroscopy\u001B[0m (SRM) applications. Here, we demonstrate the efficient conjugation of widely available secondary antibodies and cationic species to ultrasmall (sub-10 nm) \u001B[31mfluorescent\u001B[0m silica core─poly(ethylene glycol) shell (core–shell) aluminosilicate nanoparticles (aC′ dots) encapsulating different color dyes for specific targeting and high-quality fluorescence imaging of structures of the cytoskeleton (tubulin and actin) and nucleus, respectively. We show that the different color aC′ dots provide enhanced brightness and photostability relative to their parent dyes. As recently discovered, we further demonstrate that they exhibit photo-induced blinking with low ON–OFF duty cycles enabling optical SRM, for example, in the form of stochastic optical reconstruction \u001B[31mmicroscopy\u001B[0m (STORM), without the need for complex imaging setups or cocktails. After carefully optimizing Ab–aC′ dot conjugation as well as cell structure labeling protocols in fixed and permeabilized HeLa and MDA-MB-231 cells, we demonstrate three-color STORM and exemplify improved \u001B[31mresolution\u001B[0m compared to standard antibody–dye conjugates. This work paves the way to next-generation multifunctional optical \u001B[31mprobes\u001B[0m based on ultrasmall silica nanoparticle platforms for advanced applications in bioimaging, nanomedicine, and beyond.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 5 - Document ID: \u001B[32m58ec265b2c2d98f75722ed51cf4555aaf2e6ee29\u001B[0m - Score: \u001B[32m24.491175077137417\u001B[0m\n",
      "\u001B[31mFluorescent\u001B[0m Membrane Tension \u001B[31mProbes\u001B[0m for \u001B[31mSuper-\u001B[0m\u001B[31mResolution\u001B[0m \u001B[31mMicroscopy\u001B[0m: Combining Mechanosensitive Cascade Switching with Dynamic-Covalent Ketone Chemistry.\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "We report the design, synthesis, and evaluation of \u001B[31mfluorescent\u001B[0m flipper \u001B[31mprobes\u001B[0m for single-molecule \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m imaging of membrane tension in living cells. Reversible switching from bright-state ketones to dark-state hydrates, hemiacetals, and hemithioacetals is demonstrated for twisted and planarized mechanophores in solution and membranes. Broadband femtosecond fluorescence up-conversion spectroscopy evinces ultrafast chalcogen-bonding cascade switching in the excited state in solution. According to fluorescence lifetime imaging \u001B[31mmicroscopy\u001B[0m, the new flippers image membrane tension in live cells with record red shifts and photostability. Single-molecule localization \u001B[31mmicroscopy\u001B[0m with the new tension \u001B[31mprobes\u001B[0m resolves membranes well below the diffraction limit. \n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 6 - Document ID: \u001B[32m061c776f883f1ce8a8e0eaaeadd49fb0dcf87d7a\u001B[0m - Score: \u001B[32m24.058858773381186\u001B[0m\n",
      "\u001B[31mFluorescent\u001B[0m d-Amino Acids for \u001B[31mSuper-\u001B[0m\u001B[31mresolution\u001B[0m \u001B[31mMicroscopy\u001B[0m of the Bacterial Cell Wall.\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "\u001B[31mFluorescent\u001B[0m d-amino acids (FDAAs) have previously been developed to enable in situ highlighting of locations of bacterial cell wall growth. Most bacterial cells lie at the edge of the diffraction limit of visible light; thus, resolving the precise details of peptidoglycan (PG) biosynthesis requires \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m \u001B[31mmicroscopy\u001B[0m after \u001B[31mprobe\u001B[0m incorporation. Single molecule localization \u001B[31mmicroscopy\u001B[0m (SMLM) has stringent requirements on the fluorophore photophysical properties and therefore has remained challenging in this context. Here, we report the synthesis and characterization of new FDAAs compatible with one-step labeling and SMLM imaging. We demonstrate the incorporation of our \u001B[31mprobes\u001B[0m and their utility for visualizing PG at the nanoscale in Gram-negative, Gram-positive, and mycobacteria species. This improved FDAA toolkit will endow researchers with a nanoscale perspective on the spatial distribution of PG biosynthesis for a broad range of bacterial species. \n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 7 - Document ID: \u001B[32mefa2ac18f1e2d4351ee6f97e641893534cd7523e\u001B[0m - Score: \u001B[32m21.958918480718935\u001B[0m\n",
      "Engineering paralog-specific PSD-95 synthetic binders as potent and minimally invasive imaging \u001B[31mprobes\u001B[0m\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "Despite the constant advances in fluorescence imaging techniques, monitoring endogenous proteins still constitutes a major challenge in particular when considering dynamics studies or \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m imaging. We have recently evolved specific protein-based binders for PSD-95, the main postsynaptic scaffold proteins at excitatory synapses. Since the synthetic binders recognize epitopes not directly involved in the target protein activity, we consider them here as tools to develop endogenous PSD-95 imaging \u001B[31mprobes\u001B[0m. After confirming their lack of impact on PSD-95 function, we validated their use as intrabody \u001B[31mfluorescent\u001B[0m \u001B[31mprobes\u001B[0m. We further engineered the \u001B[31mprobes\u001B[0m and demonstrated their usefulness in different \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m imaging modalities (STED, PALM and DNA-PAINT) in both live and fixed neurons. Finally, we exploited the binders to enrich at the synapse genetically encoded calcium reporters. Overall, we demonstrate that these evolved binders constitute a robust and efficient platform to selectively target and monitor endogenous PSD-95 using various fluorescence imaging techniques.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 8 - Document ID: \u001B[32m1b85c7303a429feea5361256b163dccd76164dd3\u001B[0m - Score: \u001B[32m18.747745459973324\u001B[0m\n",
      "Development of a reversibly switchable \u001B[31mfluorescent\u001B[0m protein for \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m optical fluctuation imaging (SOFI).\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "Reversibly switchable \u001B[31mfluorescent\u001B[0m proteins (RSFPs) can be effectively used for \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m optical fluctuation imaging (SOFI) based on the switching and fluctuation of single molecules. Several properties of RSFPs strongly influence the quality of SOFI images. These properties include (i) the averaged fluorescence intensity in the fluctuation state, (ii) the on/off contrast ratio, (iii) the photostability, and (iv) the oligomerization tendency. The first three properties determine the fluctuation range of the imaged pixels and the SOFI signal, which are of essential importance to the spatial \u001B[31mresolution\u001B[0m, and the last may lead to artificial aggregation of target proteins. The RSFPs that are currently used for SOFI are low in averaged fluorescence intensity in the fluctuation state, photostability, and on/off contrast ratio, thereby limiting the range of application of SOFI in biological \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m imaging. In this study, we developed a novel monomeric green RSFP termed Skylan-S, which features very high photostability, contrast ratio, and averaged fluorescence intensity in the fluctuation state. Taking advantage of the excellent optical properties of Skylan-S, a 4-fold improvement in the fluctuation range of the imaged pixels and higher SOFI \u001B[31mresolution\u001B[0m can be obtained compared with Dronpa. Furthermore, \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m imaging of the actin or tubulin structures and clathrin-coated pits (CCPs) in living U2OS cells labeled with Skylan-S was demonstrated using the SOFI technique. Overall, Skylan-S developed with outstanding photochemical properties is promising for long-time SOFI imaging with high spatial-temporal \u001B[31mresolution\u001B[0m.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 9 - Document ID: \u001B[32m03a0af422dc750f2629244839862df8ed28b83d5\u001B[0m - Score: \u001B[32m17.674282459683532\u001B[0m\n",
      "Dealing with imperfection: quantifying potential length scale artefacts from nominally spherical indenter \u001B[31mprobes\u001B[0m\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "Instrumented nanoindenters are commonly employed to extract elastic, plastic or time-dependent mechanical properties of the indented material surface. In several important cases, accurate determination of the indenter \u001B[31mprobe\u001B[0m radii is essential for the proper analytical interpretation of the experimental response, and it cannot be circumvented by an experimentally determined expression for the contact area as a function of depth. Current approaches quantify the indenter \u001B[31mprobe\u001B[0m radii via inference from a series of indents on a material with known elastic modulus (e.g., fused quartz) or through the fitting of two-dimensional projected images acquired via atomic force \u001B[31mmicroscopy\u001B[0m (AFM) or scanning electron \u001B[31mmicroscopy\u001B[0m (SEM) images. Here, we propose a more robust methodology, based on concepts of differential geometry, for the accurate determination of three-dimensional indenter \u001B[31mprobe\u001B[0m geometry. The methodology is presented and demonstrated for four conospherical indenters with \u001B[31mprobe\u001B[0m radii of the order of 1–10 µm. The deviation of extracted radii with manufacturer specifications is emphasized and the limits of spherical approximations are presented. All four \u001B[31mprobes\u001B[0m deviate from the assumed spherical geometry, such that the effective radii are not independent of distance from the \u001B[31mprobe\u001B[0m apex. Significant errors in interpretation of material behaviour will result if this deviation is unaccounted for during the analysis of indentation load–depth responses obtained from material surfaces of interest, including observation of an artificial length scale that could be misinterpreted as an effect attributable to material length scales less than tens of nanometres in size or extent.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 10 - Document ID: \u001B[32m818316f18ce20c79023c9d314df8c7a9d55fd2ac\u001B[0m - Score: \u001B[32m16.814188484935467\u001B[0m\n",
      "The repositioned drugs disulfiram/diethyldithiocarbamate combined to benznidazole: Searching for Chagas disease selective therapy, preventing toxicity and drug resistance\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "Chagas disease (CD) affects at least 6 million people in 21 South American countries besides several thousand in other nations all over the world. It is estimated that at least 14,000 people die every year of CD. Since vaccines are not available, chemotherapy remains of pivotal relevance. About 30% of the treated patients cannot complete the therapy because of severe adverse reactions. Thus, the search for novel drugs is required. Here we tested the benznidazole (BZ) combination with the repositioned drug disulfiram (DSF) and its derivative diethyldithiocarbamate (DETC) upon Trypanosoma cruzi in vitro and in vivo. DETC-BZ combination was synergistic diminishing epimastigote proliferation and enhancing selective indexes up to over 10-fold. DETC was effective upon amastigotes of the BZ- partially resistant Y and the BZ-resistant Colombiana strains. The combination reduced proliferation even using low concentrations (e.g., 2.5 µM). Scanning electron \u001B[31mmicroscopy\u001B[0m revealed membrane discontinuities and cell body volume reduction. Transmission electron \u001B[31mmicroscopy\u001B[0m revealed remarkable enlargement of endoplasmic reticulum cisternae besides, dilated mitochondria with decreased electron density and disorganized kinetoplast DNA. At advanced stages, the cytoplasm vacuolation apparently impaired compartmentation. The \u001B[31mfluorescent\u001B[0m \u001B[31mprobe\u001B[0m H2-DCFDA indicates the increased production of reactive oxygen species associated with enhanced lipid peroxidation in parasites incubated with DETC. The biochemical measurement indicates the downmodulation of thiol expression. DETC inhibited \u001B[31msuperoxide\u001B[0m dismutase activity on parasites was more pronounced than in infected mice. In order to approach the DETC effects on intracellular infection, peritoneal macrophages were infected with Colombiana trypomastigotes. DETC addition diminished parasite numbers and the DETC-BZ combination was effective, despite the low concentrations used. In the murine infection, the combination significantly enhanced animal survival, decreasing parasitemia over BZ. Histopathology revealed that low doses of BZ-treated animals presented myocardial amastigote, not observed in combination-treated animals. The picrosirius collagen staining showed reduced myocardial fibrosis. Aminotransferase de aspartate, Aminotransferase de alanine, Creatine kinase, and urea plasma levels demonstrated that the combination was non-toxic. As DSF and DETC can reduce the toxicity of other drugs and resistance phenotypes, such a combination may be safe and effective.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 11 - Document ID: \u001B[32m267a9eaa54e75a7d8912152c54c30dc2550e7d85\u001B[0m - Score: \u001B[32m15.66436356437231\u001B[0m\n",
      "------------------------Menin “reads” H3K79me2 mark in a nucleosomal context------------------------\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "Methylation of histone H3 lysine-79 (H3K79) is an epigenetic mark for gene regulation in development, cellular differentiation, and disease progression. However, how this histone mark is translated into downstream effects remains poorly understood owing to a lack of knowledge about its readers. We developed a nucleosome-based photoaffinity \u001B[31mprobe\u001B[0m to capture proteins that recognize H3K79 dimethylation (H3K79me2) in a nucleosomal context. In combination with a quantitative proteomics approach, this \u001B[31mprobe\u001B[0m identified menin as a H3K79me2 reader. A cryo–electron \u001B[31mmicroscopy\u001B[0m structure of menin bound to an H3K79me2 nucleosome revealed that menin engages with the nucleosome using its fingers and palm domains and recognizes the methylation mark through a π-cation interaction. In cells, menin is selectively associated with H3K79me2 on chromatin, particularly in gene bodies. Description A reader for H3K79me2 Decoding a histone modification requires identification of proteins that “read” the mark. Methylation of histone H3 lysine-79 (H3K79) plays key roles in gene regulation, but it remains a mystery how this histone mark is recognized and interpreted by specific readers. Lin et al. identified the protein menin as a bona fide reader of H3K79me2 using a multifunctional nucleosome-based photoaffinity \u001B[31mprobe\u001B[0m. Biochemical and structural studies using cryo–electron \u001B[31mmicroscopy\u001B[0m revealed that menin engages with the H3K79me2 nucleosome through multivalent contacts. —DJ A nucleosome-based photoaffinity \u001B[31mprobe\u001B[0m identified menin as an H3K79me2 reader that binds enhancers to activate transcription.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 12 - Document ID: \u001B[32m76c165a550e4bd372c0c44f726c4da9660084dde\u001B[0m - Score: \u001B[32m15.645720369313349\u001B[0m\n",
      "A Phenylselenium-Substituted BODIPY \u001B[31mFluorescent\u001B[0m Turn-off \u001B[31mProbe\u001B[0m for Fluorescence Imaging of Hydrogen Sulfide in Living Cells.\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "Herein a phenylselenium-substituted BODIPY (1) \u001B[31mfluorescent\u001B[0m turn-off sensor was developed for the purpose to achieve excellent selectivity and sensitivity for H2S detection based on the substitution reaction of the phenylselenide group at the 3-position with H2S. The excess addition of hydrogen sulfide promoted further substitution of the phenylselenide group at the 5-position of the \u001B[31mprobe\u001B[0m and was accompanied by a further decrease in fluorescence emission intensity. Sensor 1 demonstrated remarkable performance with 49-fold red color fluorescence intensity decrease at longer excitation wavelength, a low detection limit (0.0025 μM), and specific \u001B[31mfluorescent\u001B[0m response toward H2S over anions, biothiols, and other amino acids in neutral media. It showed no obvious cell toxicity and good membrane permeability, which was well exploited for intracellular H2S detection and imaging through fluorescence \u001B[31mmicroscopy\u001B[0m imaging.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 13 - Document ID: \u001B[32m418d842e79c9df1844e38a1602e6bfc657e7cd51\u001B[0m - Score: \u001B[32m14.09540061905245\u001B[0m\n",
      "Multi-scale Xception based depthwise separable convolution for single image \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "The main target of Single image \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m is to recover high-quality or high-\u001B[31mresolution\u001B[0m image from degraded version of low-quality or low-\u001B[31mresolution\u001B[0m image. Recently, deep learning-based approaches have achieved significant performance in image \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m tasks. However, existing approaches related with image \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m fail to use the features information of low-\u001B[31mresolution\u001B[0m images as well as do not recover the hierarchical features for the final reconstruction purpose. In this research work, we have proposed a new architecture inspired by ResNet and Xception networks, which enable a significant drop in the number of network parameters and improve the processing speed to obtain the SR results. We are compared our proposed algorithm with existing state-of-the-art algorithms and confirmed the great ability to construct HR images with fine, rich, and sharp texture details as well as edges. The experimental results validate that our proposed approach has robust performance compared to other popular techniques related to accuracy, speed, and visual quality.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 14 - Document ID: \u001B[32m4588b1d60c812d1072ea341189a0300877aeb797\u001B[0m - Score: \u001B[32m13.999615028301728\u001B[0m\n",
      "Learning unsupervised feature representations for single cell \u001B[31mmicroscopy\u001B[0m images with paired cell inpainting\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "Cellular \u001B[31mmicroscopy\u001B[0m images contain rich insights about biology. To extract this information, researchers use features, or measurements of the patterns of interest in the images. Here, we introduce a convolutional neural network (CNN) to automatically design features for fluorescence \u001B[31mmicroscopy\u001B[0m. We use a selfsupervised method to learn feature representations of single cells in \u001B[31mmicroscopy\u001B[0m images without labelled training data. We train CNNs on a simple task that leverages the inherent structure of \u001B[31mmicroscopy\u001B[0m images and controls for variation in cell morphology and imaging: given one cell from an image, the CNN is asked to predict the fluorescence pattern in a second different cell from the same image. We show that our method learns high-quality features that describe protein expression patterns in single cells both yeast and human \u001B[31mmicroscopy\u001B[0m datasets. Moreover, we demonstrate that our features are useful for exploratory biological analysis, by capturing high-\u001B[31mresolution\u001B[0m cellular components in a proteome-wide cluster analysis of human proteins, and by quantifying multi-localized proteins and single-cell variability. We believe paired-cell inpainting is a generalizable method to obtain feature representations of single cells in multichannel \u001B[31mmicroscopy\u001B[0m images.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 15 - Document ID: \u001B[32mb08618311975beefb4647a9482b5f23ec65e2e39\u001B[0m - Score: \u001B[32m13.934286522959152\u001B[0m\n",
      "-------------Cell Segmentation in Images Without Structural \u001B[31mFluorescent\u001B[0m Labels-------------\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "High-content screening (HCS) provides an excellent tool to understand the mechanism of action of drugs on disease-relevant model systems. Careful selection of \u001B[31mfluorescent\u001B[0m labels (FLs) is crucial for successful HCS assay development. HCS assays typically comprise (1) FLs containing biological information of interest, and (2) additional structural FLs enabling instance segmentation for downstream analysis. However, the limited number of available fluorescence \u001B[31mmicroscopy\u001B[0m imaging channels restricts the degree to which these FLs can be experimentally multiplexed. In this paper, we present a segmentation workflow that overcomes the dependency on structural FLs for image segmentation, typically freeing 2 fluorescence \u001B[31mmicroscopy\u001B[0m channels for biologically relevant FLs. It consists in extracting structural information encoded within readouts that are primarily biological, by fine-tuning pre-trained state-of-the-art generalist cell segmentation models for different combinations of individual FLs, and aggregating the respective segmentation results together. Using annotated datasets that we provide, we confirm our methodology offers improvements in performance and robustness across several segmentation aggregation strategies and image acquisition methods, over different cell lines and various FLs. It thus enables the biological information content of HCS assays to be maximized without compromising the robustness and accuracy of computational single-cell profiling. Impact Statement This methodological paper describes a framework enabling cell segmentation for datasets without structural \u001B[31mfluorescent\u001B[0m labels to highlight cell organelles. Such capabilities favorably impact costs and possible discoveries in single-cell downstream analysis by improving our ability to incorporate more biological read-outs into a single assay. The perspective of computational and experimental biologist coauthors ensures a multidisciplinary viewpoint and accessibility for a wide readership.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 16 - Document ID: \u001B[32m73756bee616f483dcba0c30a554d5b644ac75ef9\u001B[0m - Score: \u001B[32m13.723022871410654\u001B[0m\n",
      "-Biochemical Interactions through Microscopic Techniques: Structural and Molecular Characterization-\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "Many researchers and scientists have contributed significantly to provide structural and molecular characterizations of biochemical interactions using microscopic techniques in the recent decade, as these biochemical interactions play a crucial role in the production of diverse biomaterials and the organization of biological systems. The properties, activities, and functionalities of the biomaterials and biological systems need to be identified and modified for different purposes in both the material and life sciences. The present study aimed to review the advantages and disadvantages of three main branches of \u001B[31mmicroscopy\u001B[0m techniques (optical \u001B[31mmicroscopy\u001B[0m, electron \u001B[31mmicroscopy\u001B[0m, and scanning \u001B[31mprobe\u001B[0m \u001B[31mmicroscopy\u001B[0m) developed for the characterization of these interactions. First, we explain the basic concepts of \u001B[31mmicroscopy\u001B[0m and then the breadth of their applicability to different fields of research. This work could be useful for future research works on biochemical self-assembly, biochemical aggregation and localization, biological functionalities, cell viability, live-cell imaging, material stability, and membrane permeability, among others. This understanding is of high importance in rapid, inexpensive, and accurate analysis of biochemical interactions.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 17 - Document ID: \u001B[32m2011c02ffb4ae285b04f19b5873285ae16ac35d0\u001B[0m - Score: \u001B[32m13.611871710069673\u001B[0m\n",
      "\u001B[31mSuper-\u001B[0m\u001B[31mresolution\u001B[0m reconstruction of 4D-CT lung data via patch-based low-rank matrix reconstruction\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "Lung 4D computed tomography (4D-CT), which is a time-resolved CT data acquisition, performs an important role in explicitly including respiratory motion in treatment planning and delivery. However, the radiation dose is usually reduced at the expense of inter-slice spatial \u001B[31mresolution\u001B[0m to minimize radiation-related health risk. Therefore, \u001B[31mresolution\u001B[0m enhancement along the \u001B[31msuperior\u001B[0m–inferior direction is necessary. In this paper, a \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m (SR) reconstruction method based on a patch low-rank matrix reconstruction is proposed to improve the \u001B[31mresolution\u001B[0m of lung 4D-CT images. Specifically, a low-rank matrix related to every patch is constructed by using a patch searching strategy. Thereafter, the singular value shrinkage is employed to recover the high-\u001B[31mresolution\u001B[0m patch under the constraints of the image degradation model. The output high-\u001B[31mresolution\u001B[0m patches are finally assembled to output the entire image. This method is extensively evaluated using two public data sets. Quantitative analysis shows that the proposed algorithm decreases the root mean square error by 9.7%–33.4% and the edge width by 11.4%–24.3%, relative to linear interpolation, back projection (BP) and Zhang et al’s algorithm. A new algorithm has been developed to improve the \u001B[31mresolution\u001B[0m of 4D-CT. In all experiments, the proposed method outperforms various interpolation methods, as well as BP and Zhang et al’s method, thus indicating the effectivity and competitiveness of the proposed algorithm.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 18 - Document ID: \u001B[32m2e2bb1c3238f793879b14e205225d7f4a631f740\u001B[0m - Score: \u001B[32m13.611871710069673\u001B[0m\n",
      "Combining short-axis and long-axis cardiac MR images by applying a \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m reconstruction algorithm\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "In cardiac MR images the slice thickness is normally greater than the pixel size within the slices. In general, better segmentation and analysis results can be expected for isotropic high-\u001B[31mresolution\u001B[0m (HR) data sets. If two orthogonal data sets, e. g. short-axis (SA) and long-axis (LA) volumes are combined, an increase in \u001B[31mresolution\u001B[0m can be obtained. In this work we employ a \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m reconstruction (SRR) algorithm for computing high-\u001B[31mresolution\u001B[0m data sets from two orthogonal SA and LA volumes. In contrast to a simple averaging of both data in the overlapping region, we apply a maximum a posteriori approach. There, an observation model is employed for estimating an HR image that best reproduces the two low-\u001B[31mresolution\u001B[0m input data sets. For testing the SRR approach, we use clinical MRI data with an in-plane \u001B[31mresolution\u001B[0m of 1.5 mm×1.5 mm and a slice thickness of 8 mm. We show that the results obtained with our approach are \u001B[31msuperior\u001B[0m to currently used averaging techniques. Due to the fact that the heart deforms over the cardiac cycle, we investigate further, how the replacement of a rigid registration by a deformable registration as preprocessing step improves the quality of the final HR image data. We conclude that image quality is dramatically enhanced by applying an SRR technique especially for cardiac MR images where the \u001B[31mresolution\u001B[0m in slice-selection direction is about five times lower than within the slices.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "# 19 - Document ID: \u001B[32mb85ab88443d5d8e3864d5faeff35386ea7617643\u001B[0m - Score: \u001B[32m13.537167472883873\u001B[0m\n",
      "------Hyperspectral Image \u001B[31mSuper\u001B[0m \u001B[31mResolution\u001B[0m with Real Unaligned RGB Guidance-------\n",
      "----------------------------------------------Abstract----------------------------------------------\n",
      "Fusion-based hyperspectral image (HSI) \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m has become increasingly prevalent for its capability to integrate high-frequency spatial information from the paired high-\u001B[31mresolution\u001B[0m (HR) RGB reference image. However, most of the existing methods either heavily rely on the accurate alignment between low-\u001B[31mresolution\u001B[0m (LR) HSIs and RGB images, or can only deal with simulated unaligned RGB images generated by rigid geometric transformations, which weakens their effectiveness for real scenes. In this paper, we explore the fusion-based HSI \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m with real RGB reference images that have both rigid and non-rigid misalignments. To properly address the limitations of existing methods for unaligned reference images, we propose an HSI fusion network with heterogenous feature extractions, multi-stage feature alignments, and attentive feature fusion. Specifically, our network first transforms the input HSI and RGB images into two sets of multi-scale features with an HSI encoder and an RGB encoder, respectively. The features of RGB reference images are then processed by a multi-stage alignment module to explicitly align the features of RGB reference with the LR HSI. Finally, the aligned features of RGB reference are further adjusted by an adaptive attention module to focus more on discriminative regions before sending them to the fusion decoder to generate the reconstructed HR HSI. Additionally, we collect a real-world HSI fusion dataset, consisting of paired HSI and unaligned RGB reference, to support the evaluation of the proposed model for real scenes. Extensive experiments are conducted on both simulated and our real-world datasets, and it shows that our method obtains a clear improvement over existing single-image and fusion-based \u001B[31msuper-\u001B[0m\u001B[31mresolution\u001B[0m methods on quantitative assessment as well as visual comparison.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "_ = search(ai_bio, ai_bio_trie, ai_bio_bigram_index, 'Supar-resolution macroscopy and fluorescen probes', 20,\n",
    "                 method='ltn-lnn', weight=0.9, highlight=True, print_result=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"XB Zar\" size=4>\n",
    "    <h1>\n",
    "    <b>\n",
    "     ارزیابی عملکرد سامانه (۷ + ۱۵\n",
    "     نمره)   \n",
    "     </b>\n",
    "    </h1>\n",
    "    در این قسمت تعدادی پرسمان نمونه به همراه اسناد متناظر برای آن‌ها در فایل validation در اختیار شما قرار گرفته است. در هر مورد اطلاعات لازم برای ایجاد یک پرسمان ذکر شده است. مطابق آن‌ها پرسمان خود را ایجاد کنید سپس نتایج به دست آمده از هر پرسمان را به عنوان predicted results آن پرسمان در نظر بگیرید. همچنین در هر مورد لیستی از شناسه‌ها وجود دارد. این لیست را به عنوان actual results در نظر بگیرید.\n",
    "    <br>\n",
    "    <br>\n",
    "    معیار‌های زیر را پیاده‌سازی کنید (بدون استفاده از کد آماده) و نتیجه این معیارها را روی مجموعه‌ی actual و predicted گزارش کنید. دقت کنید که به ازای هر پرسمان و همچنین مجموع پرسمان‌ها باید تمام معیارها را در قالب مشخص شده گزارش کنید.\n",
    "    <br>\n",
    "    <br>\n",
    "    در این قسمت ۷ نمره به پیاده‌سازی صحیح و ۱۵ نمره به کیفیت نهایی بازیابی مربوط می‌شود.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def calculate_precision(actual: List[List[str]], predicted: List[List[str]]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the precision of the predicted results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : List[List[str]]\n",
    "        The actual results\n",
    "    predicted : List[List[str]]\n",
    "        The predicted results\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The precision of the predicted results\n",
    "    \"\"\"\n",
    "    precision = 0.0\n",
    "\n",
    "    # TODO: Calculate precision here\n",
    "\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(actual: List[List[str]], predicted: List[List[str]]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the recall of the predicted results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : List[List[str]]\n",
    "        The actual results\n",
    "    predicted : List[List[str]]\n",
    "        The predicted results\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The recall of the predicted results\n",
    "    \"\"\"\n",
    "    recall = 0.0\n",
    "\n",
    "    # TODO: Calculate recall here\n",
    "\n",
    "    return recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_F1(actual: List[List[str]], predicted: List[List[str]]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the F1 score of the predicted results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : List[List[str]]\n",
    "        The actual results\n",
    "    predicted : List[List[str]]\n",
    "        The predicted results\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The F1 score of the predicted results    \n",
    "    \"\"\"\n",
    "    f1 = 0.0\n",
    "\n",
    "    # TODO: Calculate F1 here\n",
    "\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MAP(actual: List[List[str]], predicted: List[List[str]]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Mean Average Precision of the predicted results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : List[List[str]]\n",
    "        The actual results\n",
    "    predicted : List[List[str]]\n",
    "        The predicted results\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The Mean Average Precision of the predicted results\n",
    "    \"\"\"\n",
    "    map = 0.0\n",
    "\n",
    "    # TODO: Calculate MAP here\n",
    "\n",
    "    return map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cacluate_NDCG(actual: List[List[str]], predicted: List[List[str]]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Normalized Discounted Cumulative Gain (NDCG) of the predicted results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : List[List[str]]\n",
    "        The actual results\n",
    "    predicted : List[List[str]]\n",
    "        The predicted results\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The NDCG of the predicted results\n",
    "    \"\"\"\n",
    "    ndcg = 0.0\n",
    "\n",
    "    # TODO: Calculate NDCG here\n",
    "\n",
    "    return ndcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cacluate_MRR(actual: List[List[str]], predicted: List[List[str]]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Mean Reciprocal Rank of the predicted results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : List[List[str]]\n",
    "        The actual results\n",
    "    predicted : List[List[str]]\n",
    "        The predicted results\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The MRR of the predicted results\n",
    "    \"\"\"\n",
    "    MRR = 0.0\n",
    "\n",
    "    # TODO: Calculate MRR here\n",
    "\n",
    "    return MRR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Call evaluation functions here and report the results for ltn.lnn\n",
    "print(f\"ltn.lnn precision = {calculate_precision(None, None)}\")\n",
    "print(f\"ltn.lnn recall = {calculate_recall(None, None)}\")\n",
    "print(f\"ltn.lnn F1 = {calculate_F1(None, None)}\")\n",
    "print(f\"ltn.lnn MAP = {calculate_MAP(None, None)}\")\n",
    "print(f\"ltn.lnn NDCG = {cacluate_NDCG(None, None)}\")\n",
    "print(f\"ltn.lnn MRR = {cacluate_MRR(None, None)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Call evaluation functions here and report the results for ltc.lnc\n",
    "print(f\"ltc.lnc precision = {calculate_precision(None, None)}\")\n",
    "print(f\"ltc.lnc recall = {calculate_recall(None, None)}\")\n",
    "print(f\"ltc.lnc F1 = {calculate_F1(None, None)}\")\n",
    "print(f\"ltc.lnc MAP = {calculate_MAP(None, None)}\")\n",
    "print(f\"ltc.lnc NDCG = {cacluate_NDCG(None, None)}\")\n",
    "print(f\"ltc.lnc MRR = {cacluate_MRR(None, None)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Call evaluation functions here and report the results for Okapi BM25\n",
    "print(f\"Okapi BM25 precision = {calculate_precision(None, None)}\")\n",
    "print(f\"Okapi BM25 recall = {calculate_recall(None, None)}\")\n",
    "print(f\"Okapi BM25 F1 = {calculate_F1(None, None)}\")\n",
    "print(f\"Okapi BM25 MAP = {calculate_MAP(None, None)}\")\n",
    "print(f\"Okapi BM25 NDCG = {cacluate_NDCG(None, None)}\")\n",
    "print(f\"Okapi BM25 MRR = {cacluate_MRR(None, None)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08ac30a6a1fd2e576b33e03f7d61c3a285d7ee0582c2dd23dde6343ef303ebe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
